{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03cf21d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "from spacy.training import Example\n",
    "from spacy.scorer import Scorer\n",
    "from spacy_transformers import TransformerModel\n",
    "from typing import List, Tuple, Dict, Any, Optional, Union\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a66e0975",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    def load_data(self, \n",
    "                file_path: str,\n",
    "                text_key: str = \"text\",\n",
    "                possible_entity_keys: List[str] = [\"label\", \"entities\", \"annotations\"],\n",
    "                comment_key: str = \"Comments\") -> List[Dict]:\n",
    "        data = []\n",
    "        line_num = 0\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                for line in tqdm(f, desc=\"Download data\"):\n",
    "                    line_num += 1\n",
    "                    line = line.strip()\n",
    "                    if not line:\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        item = json.loads(line)\n",
    "                        \n",
    "                        # Check field with text\n",
    "                        if text_key not in item:\n",
    "                            print(f\"âš ï¸ Lime {line_num}: not key '{text_key}'\")\n",
    "                            continue\n",
    "                        \n",
    "                        # Find key with annotation\n",
    "                        entities = []\n",
    "                        for key in possible_entity_keys:\n",
    "                            if key in item:\n",
    "                                entities = item[key]\n",
    "                                break\n",
    "                        \n",
    "                        # Convert format\n",
    "                        unified_entities = self._convert_entities(entities, item[text_key])\n",
    "                        \n",
    "                        data.append({\n",
    "                            \"text\": item[text_key],\n",
    "                            \"entities\": unified_entities,\n",
    "                            \"comments\": item.get(comment_key, [])\n",
    "                        })\n",
    "                        \n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"Line {line_num}: Error JSON (skipped)\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Line {line_num}: {str(e)}\")\n",
    "        \n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "        \n",
    "        print(f\"Succes download {len(data)} row\")\n",
    "        return data\n",
    "    \n",
    "    def _convert_entities(self, \n",
    "                        entities: Union[List, Dict], \n",
    "                        text: str) -> List[Dict]:\n",
    "        converted = []\n",
    "        \n",
    "        if not entities:\n",
    "            return converted\n",
    "        \n",
    "        first_item = entities[0]\n",
    "        \n",
    "        # Format Doccano v1: [start, end, label]\n",
    "        if isinstance(first_item, list) and len(first_item) == 3:\n",
    "            for start, end, label in entities:\n",
    "                converted.append({\n",
    "                    \"start\": int(start),\n",
    "                    \"end\": int(end),\n",
    "                    \"label\": str(label)\n",
    "                })\n",
    "        \n",
    "        # Format Doccano v2/standart: {\"start\": X, \"end\": Y, ...}\n",
    "        elif isinstance(first_item, dict):\n",
    "            for ent in entities:\n",
    "                # Extract key\n",
    "                start_key = \"start\" if \"start\" in ent else \"start_offset\"\n",
    "                end_key = \"end\" if \"end\" in ent else \"end_offset\"\n",
    "                label_key = \"label\" if \"label\" in ent else \"tag\"\n",
    "                \n",
    "                converted.append({\n",
    "                    \"start\": int(ent[start_key]),\n",
    "                    \"end\": int(ent[end_key]),\n",
    "                    \"label\": str(ent[label_key])\n",
    "                })\n",
    "        \n",
    "        return converted\n",
    "    \n",
    "    def prepare_data(self, \n",
    "                    data: List[Dict],\n",
    "                    validate: bool = True) -> List[Tuple[str, Dict]]:\n",
    "        formatted_data = []\n",
    "        error_count = 0\n",
    "        \n",
    "        for item in tqdm(data, desc=\"Prepare data\"):\n",
    "            try:\n",
    "                text = item[\"text\"]\n",
    "                entities = []\n",
    "                \n",
    "                for ent in item[\"entities\"]:\n",
    "                    start = ent[\"start\"]\n",
    "                    end = ent[\"end\"]\n",
    "                    label = ent[\"label\"]\n",
    "                    \n",
    "                    if validate:\n",
    "                        # Check correct annotation\n",
    "                        if not (0 <= start <= end <= len(text)):\n",
    "                            raise ValueError(\n",
    "                                f\"Incorrect position: {start}-{end} \"\n",
    "                                f\"for text line {len(text)}. Text: '{text[start:end]}'\"\n",
    "                            )\n",
    "                        \n",
    "                        # Check mark not empty\n",
    "                        if not label.strip():\n",
    "                            raise ValueError(f\"Empty mark for position {start}-{end}\")\n",
    "                    \n",
    "                    entities.append((start, end, label))\n",
    "                \n",
    "                formatted_data.append((text, {\"entities\": entities}))\n",
    "            except Exception as e:\n",
    "                error_count += 1\n",
    "                print(f\"Error in element: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        if error_count > 0:\n",
    "            print(f\"ðŸ”´ All error number: {error_count} (Ð¸Ð· {len(data)})\")\n",
    "        \n",
    "        return formatted_data\n",
    "\n",
    "    def save_to_jsonl(self, \n",
    "                     data: List[Dict], \n",
    "                     output_path: str,\n",
    "                     format: str = \"doccano\") -> None:\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for item in tqdm(data, desc=\"Saved data\"):\n",
    "                if format == \"doccano\":\n",
    "                    # Format Doccano: {\"text\": \"...\", \"label\": [[start, end, tag], ...]}\n",
    "                    labels = [\n",
    "                        [ent[\"start\"], ent[\"end\"], ent[\"label\"]]\n",
    "                        for ent in item[\"entities\"]\n",
    "                    ]\n",
    "                    json.dump({\n",
    "                        \"text\": item[\"text\"],\n",
    "                        \"label\": labels,\n",
    "                        \"Comments\": item.get(\"comments\", [])\n",
    "                    }, f, ensure_ascii=False)\n",
    "                else:\n",
    "                    # Standart format\n",
    "                    json.dump(item, f, ensure_ascii=False)\n",
    "                f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd5f2bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Clear text\"\"\"\n",
    "    text = re.sub(r'\\n+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def adjust_annotations(text, annotations):\n",
    "    \"\"\"Correct annotation\"\"\"\n",
    "    cleaned_text = clean_text(text)\n",
    "    new_entities = []\n",
    "    \n",
    "    # Create list (start, end, label, entity_text)\n",
    "    entities_info = [(start, end, label, text[start:end]) \n",
    "                    for start, end, label in annotations['entities']]\n",
    "    \n",
    "    # Sort entity\n",
    "    entities_info.sort(key=lambda x: x[0])\n",
    "    \n",
    "    for start, end, label, entity_text in entities_info:\n",
    "        occurrences = [m.start() for m in re.finditer(re.escape(entity_text), text)]\n",
    "        \n",
    "        for occ_start in occurrences:\n",
    "            if occ_start == start:  \n",
    "                new_start = cleaned_text.find(entity_text)\n",
    "                if new_start != -1:\n",
    "                    new_end = new_start + len(entity_text)\n",
    "                    new_entities.append((new_start, new_end, label))\n",
    "                    cleaned_text = cleaned_text[:new_start] + ' ' * len(entity_text) + cleaned_text[new_end:]\n",
    "                break\n",
    "    \n",
    "    return {'entities': new_entities}\n",
    "\n",
    "class NERTrainer:\n",
    "    def __init__(self, \n",
    "                 model_name: str = \"ru_core_news_sm\", \n",
    "                 use_gpu: bool = True,\n",
    "                 blank_language: str = \"ru\",\n",
    "                 disable_pipes: Optional[List[str]] = None,\n",
    "                 transformer_name: Optional[str] = None):\n",
    "        self.use_gpu = use_gpu\n",
    "        self._setup_device()\n",
    "        \n",
    "        if transformer_name:\n",
    "            self.nlp = self._create_transformer_model(blank_language, transformer_name)\n",
    "        else:\n",
    "            self.nlp = self._load_model(model_name, blank_language, disable_pipes)\n",
    "            \n",
    "        self.ner = self._setup_ner_pipe(transformer_name)\n",
    "\n",
    "    def _create_transformer_model(self, lang: str, transformer_name: str):\n",
    "        \"\"\"Create model with transformer\"\"\"\n",
    "        nlp = spacy.blank(lang)\n",
    "        \n",
    "        # Add component transformer\n",
    "        config = {\n",
    "            \"model\": {\n",
    "                \"@architectures\": \"spacy-transformers.TransformerModel.v3\",\n",
    "                \"name\": transformer_name,\n",
    "                \"tokenizer_config\": {\"use_fast\": True},\n",
    "                \"transformer_config\": {\"output_hidden_states\": True}\n",
    "            }\n",
    "        }\n",
    "        nlp.add_pipe(\"transformer\", config=config)\n",
    "        \n",
    "        print(f\"Create transformer model {transformer_name}\")\n",
    "        return nlp\n",
    "        \n",
    "    def _setup_device(self) -> None:\n",
    "        \"\"\"Setting device (CPU/GPU)\"\"\"\n",
    "        if self.use_gpu and spacy.prefer_gpu():\n",
    "            spacy.require_gpu()\n",
    "            print(\"Used GPU\")\n",
    "        else:\n",
    "            print(\"âš ï¸ GPU not found, used CPU\")\n",
    "    \n",
    "    def _load_model(self, model_name: str, blank_language: str, disable_pipes: List[str]):\n",
    "        \"\"\"Load model and processing error\"\"\"\n",
    "        try:\n",
    "            if model_name.lower() == \"blank\":\n",
    "                return spacy.blank(blank_language)\n",
    "            elif Path(model_name).exists():\n",
    "                return spacy.load(model_name, disable=disable_pipes or [])\n",
    "            else:\n",
    "                return spacy.load(model_name, disable=disable_pipes or [])\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Model not found '{model_name}': {str(e)}\")\n",
    "    \n",
    "    def _setup_ner_pipe(self, transformer_name):\n",
    "        \"\"\"Setting NER component with transformer\"\"\"\n",
    "        if \"ner\" in self.nlp.pipe_names:\n",
    "            return self.nlp.get_pipe(\"ner\")\n",
    "    \n",
    "        # Ð”For transformer model\n",
    "        if \"transformer\" in self.nlp.pipe_names:\n",
    "            return self.nlp.add_pipe(\n",
    "                \"ner\",\n",
    "                after=\"transformer\",\n",
    "                config={\n",
    "                    \"model\": {\n",
    "                        \"@architectures\": \"spacy.TransitionBasedParser.v2\",\n",
    "                        \"hidden_width\": 128,\n",
    "                        \"maxout_pieces\": 2,\n",
    "                        \"use_upper\": True\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "    \n",
    "        # For simple model\n",
    "        return self.nlp.add_pipe(\"ner\")\n",
    "    \n",
    "    def prepare_data(self, \n",
    "                    data: List[Dict],\n",
    "                    text_key: str = \"text\",\n",
    "                    entities_key: str = \"label\",\n",
    "                    start_offset_key: str = \"start_offset\",\n",
    "                    end_offset_key: str = \"end_offset\",\n",
    "                    label_key: str = \"label\") -> List[Tuple[str, Dict]]:\n",
    "        formatted_data = []\n",
    "        error_count = 0\n",
    "        \n",
    "        for item in tqdm(data, desc=\"Data preparation\"):\n",
    "            try:\n",
    "                text = item[text_key]\n",
    "                entities = []\n",
    "                \n",
    "                for ent in item.get(entities_key, []):\n",
    "                    # Check correct annotation\n",
    "                    if not all(k in ent for k in [start_offset_key, end_offset_key, label_key]):\n",
    "                        raise ValueError(f\"Incorrect annotation: {ent}\")\n",
    "                    \n",
    "                    start = ent[start_offset_key]\n",
    "                    end = ent[end_offset_key]\n",
    "                    \n",
    "                    # Validate position\n",
    "                    if not (0 <= start <= end <= len(text)):\n",
    "                        raise ValueError(f\"Incorrect position: {start}-{end} for text length {len(text)}\")\n",
    "                    \n",
    "                    entities.append((start, end, ent[label_key]))\n",
    "                \n",
    "                formatted_data.append((text, {\"entities\": entities}))\n",
    "            except Exception as e:\n",
    "                error_count += 1\n",
    "                print(f\"Error in element: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        if error_count > 0:\n",
    "            print(f\"All error count: {error_count} (for {len(data)})\")\n",
    "        \n",
    "        return formatted_data\n",
    "    \n",
    "    def train_test_split(self, \n",
    "                       data: List,\n",
    "                       test_size: float = 0.2,\n",
    "                       random_state: Optional[int] = None) -> Tuple[List, List]:\n",
    "        if random_state is not None:\n",
    "            random.seed(random_state)\n",
    "            \n",
    "        if not 0 < test_size < 1:\n",
    "            raise ValueError(\"test_size must be between 0 and 1\")\n",
    "            \n",
    "        shuffled = random.sample(data, len(data))\n",
    "        split_idx = int(len(data) * (1 - test_size))\n",
    "        return shuffled[:split_idx], shuffled[split_idx:]\n",
    "    \n",
    "    def add_labels(self, \n",
    "                  data: Optional[List[Tuple[str, Dict]]] = None,\n",
    "                  labels: Optional[List[str]] = None) -> None:\n",
    "        if labels is not None:\n",
    "            unique_labels = set(labels)\n",
    "        elif data is not None:\n",
    "            unique_labels = set()\n",
    "            for _, annotations in data:\n",
    "                for _, _, label in annotations[\"entities\"]:\n",
    "                    unique_labels.add(label)\n",
    "        else:\n",
    "            raise ValueError(\"You need data or labels\")\n",
    "        \n",
    "        for label in unique_labels:\n",
    "            self.ner.add_label(label)\n",
    "        \n",
    "        print(f\"Added labels: {sorted(unique_labels)}\")\n",
    "    \n",
    "    def train(self, \n",
    "             train_data: List[Tuple[str, Dict]],\n",
    "             epochs: int = 10,\n",
    "             batch_size: int = 8,\n",
    "             dropout: float = 0.5,\n",
    "             learning_rate: float = 0.001,\n",
    "             save_path: Optional[str] = None,\n",
    "             eval_data: Optional[List[Tuple[str, Dict]]] = None,\n",
    "             early_stopping: Optional[int] = None):\n",
    "    \n",
    "        # Init optimizer\n",
    "        optimizer = self.nlp.initialize()\n",
    "    \n",
    "        # Setting parameters for transformers\n",
    "        if \"transformer\" in self.nlp.pipe_names:\n",
    "            batch_size = min(batch_size, 4)\n",
    "            learning_rate = 1e-4\n",
    "            dropout = 0.1\n",
    "    \n",
    "        # Install learning rate\n",
    "        if hasattr(optimizer, \"learn_rate\"):\n",
    "            optimizer.learn_rate = learning_rate\n",
    "    \n",
    "        # init progress bar settings\n",
    "        best_f1 = -1\n",
    "        best_epoch = 0\n",
    "        history = {\"loss\": [], \"f1\": []}\n",
    "    \n",
    "        # Cycle train \n",
    "        for epoch in range(epochs):\n",
    "            losses = {}\n",
    "            random.shuffle(train_data)\n",
    "        \n",
    "            # Butch proccessing\n",
    "            batches = [train_data[i:i+batch_size] for i in range(0, len(train_data), batch_size)]\n",
    "        \n",
    "            for batch in tqdm(batches, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "                examples = []\n",
    "                for text, annotations in batch:\n",
    "                    doc = self.nlp.make_doc(text)\n",
    "                    example = Example.from_dict(doc, annotations)\n",
    "                    examples.append(example)\n",
    "            \n",
    "                self.nlp.update(examples, drop=dropout, losses=losses, sgd=optimizer)\n",
    "        \n",
    "            # Log and validation\n",
    "            epoch_loss = losses.get(\"ner\", 0)\n",
    "            history[\"loss\"].append(epoch_loss)\n",
    "            print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "            print(f\"ðŸ“‰ Loss: {epoch_loss:.3f}\")\n",
    "        \n",
    "            if eval_data:\n",
    "                metrics = self.evaluate(eval_data, verbose=False)\n",
    "                avg_f1 = sum(m[\"f\"] for m in metrics.values()) / len(metrics)\n",
    "                history[\"f1\"].append(avg_f1)\n",
    "                print(f\"ðŸ“Š F1-score: {avg_f1:.3f}\")\n",
    "            \n",
    "                if save_path and avg_f1 > best_f1:\n",
    "                    best_f1 = avg_f1\n",
    "                    best_epoch = epoch\n",
    "                    self.nlp.to_disk(save_path)\n",
    "                    print(f\"Saved best model (F1: {best_f1:.3f})\")\n",
    "            \n",
    "                if early_stopping and (epoch - best_epoch) >= early_stopping:\n",
    "                    print(f\"ðŸ›‘ Early stopping after {early_stopping} epoch with improvement\")\n",
    "                    break\n",
    "    \n",
    "        if eval_data is None and save_path:\n",
    "            self.nlp.to_disk(save_path)\n",
    "            print(\"Saved final model\")\n",
    "    \n",
    "        return history\n",
    "    \n",
    "    def evaluate(self, test_data: List[Tuple[str, Dict]], verbose: bool = True) -> Dict:\n",
    "        true_entities = []\n",
    "        pred_entities = []\n",
    "    \n",
    "        for text, annotations in tqdm(test_data, desc=\"ðŸ” ÐžÑ†ÐµÐ½ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸\"):\n",
    "            # Entity from annotation\n",
    "            true = [(start, end, label) for start, end, label in annotations[\"entities\"]]\n",
    "            true_entities.append((text, true))\n",
    "        \n",
    "            # predicted entity\n",
    "            doc = self.nlp(text)\n",
    "            pred = [(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]\n",
    "            pred_entities.append((text, pred))\n",
    "    \n",
    "        # Calc metrics\n",
    "        metrics = self._calculate_metrics(true_entities, pred_entities)\n",
    "    \n",
    "        if verbose:\n",
    "            self._print_detailed_metrics(metrics)\n",
    "    \n",
    "        return metrics\n",
    "\n",
    "    def _calculate_metrics(self, true_entities, pred_entities):\n",
    "        \"\"\"Calc metrics for entities\"\"\"\n",
    "        metrics = defaultdict(lambda: {\"tp\": 0, \"fp\": 0, \"fn\": 0})\n",
    "    \n",
    "        for (true_text, true), (pred_text, pred) in zip(true_entities, pred_entities):\n",
    "            # Check position in text\n",
    "            if true_text != pred_text:\n",
    "                raise ValueError(\"The texts don't match!\")\n",
    "        \n",
    "            true_set = set(true)\n",
    "            pred_set = set(pred)\n",
    "        \n",
    "            # Calc TP, FP, FN for entity type\n",
    "            for label in set([e[2] for e in true] + [e[2] for e in pred]):\n",
    "                tp = len([e for e in true if e in pred and e[2] == label])\n",
    "                fp = len([e for e in pred if e not in true and e[2] == label])\n",
    "                fn = len([e for e in true if e not in pred and e[2] == label])\n",
    "            \n",
    "                metrics[label][\"tp\"] += tp\n",
    "                metrics[label][\"fp\"] += fp\n",
    "                metrics[label][\"fn\"] += fn\n",
    "    \n",
    "        # Calc precision, recall, f1 for each entity type\n",
    "        result = {}\n",
    "        for label, counts in metrics.items():\n",
    "            tp, fp, fn = counts[\"tp\"], counts[\"fp\"], counts[\"fn\"]\n",
    "            p = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            r = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            f1 = 2 * (p * r) / (p + r) if (p + r) > 0 else 0\n",
    "        \n",
    "            result[label] = {\n",
    "                \"precision\": p,\n",
    "                \"recall\": r,\n",
    "                \"f1\": f1,\n",
    "                \"support\": tp + fn,\n",
    "                \"tp\": tp,\n",
    "                \"fp\": fp,\n",
    "                \"fn\": fn\n",
    "            }\n",
    "    \n",
    "        return result\n",
    "\n",
    "    def _print_detailed_metrics(self, metrics):\n",
    "        print(\"\\nMetrics details:\")\n",
    "        print(\"{:<20} {:<10} {:<10} {:<10} {:<10}\".format(\n",
    "            \"Ð¢Ð¸Ð¿\", \"Precision\", \"Recall\", \"F1\", \"Support\"))\n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "        for label, values in metrics.items():\n",
    "            print(\"{:<20} {:<10.3f} {:<10.3f} {:<10.3f} {:<10}\".format(\n",
    "                label,\n",
    "                values[\"precision\"],\n",
    "                values[\"recall\"],\n",
    "                values[\"f1\"],\n",
    "                values[\"support\"]))\n",
    "    \n",
    "        # Micro-average\n",
    "        total_tp = sum(m[\"tp\"] for m in metrics.values())\n",
    "        total_fp = sum(m[\"fp\"] for m in metrics.values())\n",
    "        total_fn = sum(m[\"fn\"] for m in metrics.values())\n",
    "    \n",
    "        micro_p = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0\n",
    "        micro_r = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
    "        micro_f1 = 2 * (micro_p * micro_r) / (micro_p + micro_r) if (micro_p + micro_r) > 0 else 0\n",
    "    \n",
    "        print(\"\\nTotal final metrics (micro-average):\")\n",
    "        print(f\"Precision: {micro_p:.3f}\")\n",
    "        print(f\"Recall: {micro_r:.3f}\")\n",
    "        print(f\"F1-score: {micro_f1:.3f}\")\n",
    "\n",
    "    def _print_detailed_metrics(self, metrics):\n",
    "        \"\"\"Details\"\"\"\n",
    "        print(\"\\nDetails:\")\n",
    "        print(\"{:<20} {:<10} {:<10} {:<10} {:<10}\".format(\n",
    "            \"Ð¢Ð¸Ð¿\", \"Precision\", \"Recall\", \"F1\", \"Support\"))\n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "        for label, values in metrics.items():\n",
    "            print(\"{:<20} {:<10.3f} {:<10.3f} {:<10.3f} {:<10}\".format(\n",
    "                label,\n",
    "                values[\"precision\"],\n",
    "                values[\"recall\"],\n",
    "                values[\"f1\"],\n",
    "                values[\"support\"]))\n",
    "    \n",
    "        # Micro-average\n",
    "        total_tp = sum(m[\"tp\"] for m in metrics.values())\n",
    "        total_fp = sum(m[\"fp\"] for m in metrics.values())\n",
    "        total_fn = sum(m[\"fn\"] for m in metrics.values())\n",
    "    \n",
    "        micro_p = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0\n",
    "        micro_r = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
    "        micro_f1 = 2 * (micro_p * micro_r) / (micro_p + micro_r) if (micro_p + micro_r) > 0 else 0\n",
    "    \n",
    "        print(\"\\nTotal final metrics (micro-average):\")\n",
    "        print(f\"Precision: {micro_p:.3f}\")\n",
    "        print(f\"Recall: {micro_r:.3f}\")\n",
    "        print(f\"F1-score: {micro_f1:.3f}\")\n",
    "    \n",
    "    def predict(self, \n",
    "               text: str,\n",
    "               return_doc: bool = False) -> Union[List[Tuple[str, str, int, int]], \"spacy.tokens.Doc\"]:\n",
    "        doc = self.nlp(text)\n",
    "        if return_doc:\n",
    "            return doc\n",
    "        return [(ent.text, ent.label_, ent.start_char, ent.end_char) for ent in doc.ents]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b26a7a92-6fa2-4d49-b646-b33b7d576b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e9cf94222941799f930fb9bbe7d34b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload data: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succes upload 2051 rows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b5e5f31b26431da3379f7dccac48a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload data: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succes upload 879 raw\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2f810b62b046828367c84a81e3b1ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prepare data:   0%|          | 0/2051 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in element: incorrect position: 117-121 for text length 114. Text: ''\n",
      "Error in element: incorrect position: 262-267 for text length 259. Text: ''\n",
      "Total error count: 2 (from 2051)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5d7f74fcef4840aa8c2e4d4b8c3976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prepare data:   0%|          | 0/879 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ GPU not support, used CPU\n",
      "ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð¾Ð±ÑƒÑ‡Ð°ÑŽÑ‰Ð¸Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…: [('Ð»Ð¸ÑÑ‚ Ð½ÐµÑ€Ð¶Ð°Ð²ÐµÑŽÑ‰Ð¸Ð¹ 4 x 1500 x 3000 mm aisi 201 12Ñ…15Ð³9Ð½Ð´ Ð³ / Ðº Ð¼Ð°Ñ‚Ð¾Ð²Ñ‹Ð¹\\n\\n\\nÐ»Ð¸ÑÑ‚ Ð½ÐµÑ€Ð¶Ð°Ð²ÐµÑŽÑ‰Ð¸Ð¹ 8 x 1500 x 3000 mm aisi 201 12Ñ…15Ð³9Ð½Ð´ Ð³ / Ðº Ð¼Ð°Ñ‚Ð¾Ð²Ñ‹Ð¹\\n\\n\\nÐ»Ð¸ÑÑ‚ Ð½ÐµÑ€Ð¶Ð°Ð²ÐµÑŽÑ‰Ð¸Ð¹ 1.5 x 1000 x 2000 mm aisi 201 12Ñ…15Ð³9Ð½Ð´ Ñ… / Ðº ÑˆÐ»Ð¸Ñ„Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹\\n\\n\\nÐ»Ð¸ÑÑ‚ Ð½ÐµÑ€Ð¶Ð°Ð²ÐµÑŽÑ‰Ð¸Ð¹ 2 x 1000 x 2000 mm aisi 201 12Ñ…15Ð³9Ð½Ð´ Ð³ / Ðº Ð¿Ñ€Ð¾ÑÐµÑ‡Ð½Ð¾ - Ð²Ñ‹Ñ‚ÑÐ¶Ð½Ð¾Ð¹ Ð¿Ð²Ð»\\n\\n\\nÐ»Ð¸ÑÑ‚ Ð½ÐµÑ€Ð¶Ð°Ð²ÐµÑŽÑ‰Ð¸Ð¹ 4 x 1000 x 2000 mm aisi 201 12Ñ…15Ð³9Ð½Ð´ Ð³ / Ðº Ð¿Ñ€Ð¾ÑÐµÑ‡Ð½Ð¾ - Ð²Ñ‹Ñ‚ÑÐ¶Ð½Ð¾Ð¹ Ð¿Ð²Ð»', {'entities': [(0, 4, 'product'), (5, 16, 'material'), (17, 18, 'thickness'), (21, 25, 'width'), (28, 32, 'length'), (36, 44, 'mark_steel_aisi'), (45, 54, 'mark_steal'), (55, 60, 'tehnology'), (61, 68, 'color'), (71, 75, 'product'), (76, 87, 'material'), (88, 89, 'thickness'), (92, 96, 'width'), (99, 103, 'length'), (107, 115, 'mark_steel_aisi'), (116, 125, 'mark_steal'), (126, 131, 'tehnology'), (132, 139, 'color'), (142, 146, 'product'), (147, 158, 'material'), (159, 162, 'thickness'), (165, 169, 'width'), (172, 176, 'length'), (180, 188, 'mark_steel_aisi'), (189, 198, 'mark_steal'), (199, 204, 'tehnology'), (205, 216, 'coating'), (219, 223, 'product'), (224, 235, 'material'), (236, 237, 'thickness'), (240, 244, 'width'), (247, 251, 'length'), (255, 263, 'mark_steel_aisi'), (264, 273, 'mark_steal'), (274, 279, 'tehnology'), (280, 299, 'type'), (300, 303, 'mark'), (306, 310, 'product'), (311, 322, 'material'), (323, 324, 'thickness'), (327, 331, 'width'), (334, 338, 'length'), (342, 350, 'mark_steel_aisi'), (351, 360, 'mark_steal'), (361, 366, 'tehnology'), (367, 386, 'type'), (387, 390, 'mark')]})]\n",
      "Apply metrics: ['coating', 'color', 'country', 'form', 'height', 'height_big', 'height_small', 'inner_diameter', 'length', 'manufacturer', 'mark', 'mark_steal', 'mark_steel_aisi', 'material', 'outer_diameter', 'package', 'precision', 'product', 'purpose', 'standart_en', 'standart_gost', 'standart_tu', 'strength_class', 'strength_class_old', 'tehnology', 'thickness', 'type', 'width']\n",
      "\n",
      "Train data length: 2049\n",
      "Test data length: 879\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8736150e56f143d68dd9d40097754ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/40\n",
      "ðŸ“‰ Loss: 34751.421\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a09d3a2c05b4756ab28d451cc455b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/40\n",
      "ðŸ“‰ Loss: 17453.279\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80f6b6e74fc4bbe875152dc0d5f83b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ð­Ð¿Ð¾Ñ…Ð° 3/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/40\n",
      "ðŸ“‰ Loss: 13180.380\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c541b3978be4c6a961f2dcf3df64576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/40\n",
      "ðŸ“‰ Loss: 11255.004\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a428833b9a394656a25ff6aa4e421d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/40\n",
      "ðŸ“‰ Loss: 9928.187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44022b1976d04dc995bdee0a94f00c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/40\n",
      "ðŸ“‰ Loss: 9012.005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068a4c6193684fb3b0b9e9f878f091e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/40\n",
      "ðŸ“‰ Loss: 7986.002\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2e50bdad1844b09d1d33b43aa77fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/40\n",
      "ðŸ“‰ Loss: 7156.043\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e776713e4b814e2fbe5c44b4652513e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/40\n",
      "ðŸ“‰ Loss: 6830.694\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d5bdb15110d4fcca312d70cbcfae6a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/40\n",
      "ðŸ“‰ Loss: 6312.031\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa075c36c44748dd9e24b5f5d6f37e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/40\n",
      "ðŸ“‰ Loss: 5962.034\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633c4ebfaa1543e59c41f9aa472e469b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/40\n",
      "ðŸ“‰ Loss: 5555.889\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8d8acc731c45f69e688123146456ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13/40\n",
      "ðŸ“‰ Loss: 5437.939\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a68f4c3e5cc4ba98183aa2ffb5281df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/40\n",
      "ðŸ“‰ Loss: 5274.134\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5283747d4d3445c0af6a26fd0eaa9db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ð­Ð¿Ð¾Ñ…Ð° 15/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/40\n",
      "ðŸ“‰ Loss: 4979.238\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a0fbe8342741f089f462cde6c36f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16/40\n",
      "ðŸ“‰ Loss: 4765.407\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e069ff33954783940a418a170c1b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17/40\n",
      "ðŸ“‰ Loss: 4654.535\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd5f7ff59204ae6add7a59f28ce38c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18/40\n",
      "ðŸ“‰ Loss: 4375.937\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea356d05c964fd78ed4754397226626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19/40\n",
      "ðŸ“‰ Loss: 4364.238\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7d80bf3f6149589c72a8c1e3468dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/40\n",
      "ðŸ“‰ Loss: 4283.655\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19105e13583c42359bafa5951383345e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21/40\n",
      "ðŸ“‰ Loss: 4241.335\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f7c92c14e04350917c14f362c25fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22/40\n",
      "ðŸ“‰ Loss: 3984.289\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9c5e8c1f384da986be1dde6fb42449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23/40\n",
      "ðŸ“‰ Loss: 3888.364\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50fb175a3a442dab72c8200c07f05d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24/40\n",
      "ðŸ“‰ Loss: 4042.827\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c617cc64a704693ad63f87acbc0b7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25/40\n",
      "ðŸ“‰ Loss: 3962.687\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38674991f20842f38cecb8eab3a8dea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26/40\n",
      "ðŸ“‰ Loss: 3801.571\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e2a3d4ad654460a4f51bd32bddb197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27/40\n",
      "ðŸ“‰ Loss: 3854.330\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611b61d6d4eb4397bfb80b05870c6fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28/40\n",
      "ðŸ“‰ Loss: 3610.508\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aedf68188da2474f9f1a76a375383932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29/40\n",
      "ðŸ“‰ Loss: 3688.979\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c48fa188e8b84cd28dc8a9fc1694e343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30/40\n",
      "ðŸ“‰ Loss: 3604.925\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111d4cc6241540b690b2bffb49881856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 31/40\n",
      "ðŸ“‰ Loss: 3501.070\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae89017396ca42069d693329dbdad7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32/40\n",
      "ðŸ“‰ Loss: 3567.380\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7585bfccbe844ca9aaff8430256b5d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 33/40\n",
      "ðŸ“‰ Loss: 3380.647\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8409318a33454a9d8ab0192ffc372b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34/40\n",
      "ðŸ“‰ Loss: 3541.794\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c6c668b6274ee589c40410086fa51f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 35/40\n",
      "ðŸ“‰ Loss: 3528.954\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90df10d278bf4bb1aaccaf3b7123a5e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 36/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36/40\n",
      "ðŸ“‰ Loss: 3452.260\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3ccbbee28c453aa305e29b7afb31a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 37/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 37/40\n",
      "ðŸ“‰ Loss: 3507.874\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa16d02a4594bfbb2c6fb6b14314f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 38/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38/40\n",
      "ðŸ“‰ Loss: 3424.018\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4f5b56be8648eb88922e70677f5ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 39/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 39/40\n",
      "ðŸ“‰ Loss: 3345.640\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa9f60aa8704890aae4a5c888787f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 40/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40/40\n",
      "ðŸ“‰ Loss: 3399.545\n",
      "Saved final model\n",
      "Train time:  7203.317417383194  c\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f683e04784fb4fa5b21ecd13cc2f0566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ðŸ” Evaluate model:   0%|          | 0/879 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Details:\n",
      "Ð¢Ð¸Ð¿                  Precision  Recall     F1         Support \n",
      "------------------------------------------------------------\n",
      "length               0.965      0.953      0.959      1236      \n",
      "tehnology            0.977      0.977      0.977      1017      \n",
      "product              0.994      0.991      0.993      4421      \n",
      "thickness            0.991      0.989      0.990      2812      \n",
      "color                0.960      0.960      0.960      100       \n",
      "coating              0.970      0.959      0.965      171       \n",
      "mark_steal           0.980      0.979      0.980      2724      \n",
      "material             0.980      0.992      0.986      1940      \n",
      "mark_steel_aisi      0.988      0.988      0.988      603       \n",
      "width                0.967      0.975      0.971      1869      \n",
      "type                 0.982      0.989      0.985      1862      \n",
      "mark                 0.915      0.933      0.924      403       \n",
      "height               0.942      0.921      0.931      579       \n",
      "form                 0.995      0.978      0.986      224       \n",
      "standart_gost        0.986      0.990      0.988      1525      \n",
      "manufacturer         0.933      0.947      0.940      132       \n",
      "country              0.958      0.920      0.939      25        \n",
      "standart_en          0.981      0.990      0.986      310       \n",
      "package              0.967      0.967      0.967      30        \n",
      "inner_diameter       0.975      0.982      0.978      1460      \n",
      "purpose              0.947      0.857      0.900      42        \n",
      "height_big           0.898      0.934      0.916      198       \n",
      "standart_tu          1.000      1.000      1.000      84        \n",
      "outer_diameter       0.971      0.948      0.959      524       \n",
      "strength_class       0.966      0.911      0.938      124       \n",
      "strength_class_old   0.905      0.987      0.944      77        \n",
      "height_small         1.000      0.111      0.200      9         \n",
      "precision            1.000      1.000      1.000      40        \n",
      "\n",
      "total metric (micro-average):\n",
      "Precision: 0.979\n",
      "Recall: 0.979\n",
      "F1-score: 0.979\n",
      "\n",
      "Metrics in total:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to dict.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m metrics \u001b[38;5;241m=\u001b[39m trainer_blank_empty\u001b[38;5;241m.\u001b[39mevaluate(formatted_test)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð½Ð° Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð¹ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐµ:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1-score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported format string passed to dict.__format__"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "processor = DataProcessor()\n",
    "\n",
    "# Upload data\n",
    "train_data = processor.load_data(\"../../data/jsonl/dataset_jsonl_train.jsonl\")\n",
    "test_data = processor.load_data(\"../../data/jsonl/dataset_jsonl_test.jsonl\")\n",
    "\n",
    "# ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ\n",
    "formatted_train = processor.prepare_data(train_data)\n",
    "formatted_test = processor.prepare_data(test_data) if test_data else None\n",
    "\n",
    "time_start = time.time()\n",
    "# Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ñ‚Ñ€ÐµÐ½ÐµÑ€Ð°\n",
    "trainer_blank_empty = NERTrainer(\n",
    "    model_name=\"blank\",\n",
    "    blank_language=\"ru\",\n",
    ")\n",
    "\n",
    "# Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¼ÐµÑ‚Ð¾Ðº Ð”Ðž Ñ€Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ñ (Ñ‚ÐµÐ¿ÐµÑ€ÑŒ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²Ð»ÐµÐ½Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ)\n",
    "print(\"ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð¾Ð±ÑƒÑ‡Ð°ÑŽÑ‰Ð¸Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…:\", formatted_train[:1])  # Ð¿Ð¾ÐºÐ°Ð¶ÐµÐ¼ Ð¿ÐµÑ€Ð²Ñ‹Ð¹ Ð¿Ñ€Ð¸Ð¼ÐµÑ€ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸\n",
    "trainer_blank_empty.add_labels(formatted_train)\n",
    "\n",
    "print(f\"\\nÐ Ð°Ð·Ð¼ÐµÑ€ Ð¾Ð±ÑƒÑ‡Ð°ÑŽÑ‰ÐµÐ¹ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ¸: {len(formatted_train)}\")\n",
    "print(f\"Ð Ð°Ð·Ð¼ÐµÑ€ Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð¹ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ¸: {len(formatted_test) if formatted_test else 0}\")\n",
    "\n",
    "# ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ (ÑƒÐ²ÐµÐ»Ð¸Ñ‡Ð¸Ð¼ epochs Ð´Ð»Ñ Ð»ÑƒÑ‡ÑˆÐµÐ³Ð¾ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð°)\n",
    "trainer_blank_empty.train(\n",
    "    formatted_train, \n",
    "    epochs=40,\n",
    "    batch_size=1,  \n",
    "    save_path=r\"C:\\Users\\mezhonnyy\\Desktop\\Ð ÐµÑˆÐµÐ½Ð¸Ñ\\NER\\model\\NER_final\\data\\jsonl\\model\"\n",
    ")\n",
    "print('Train time: ', time.time() - time_start, ' c')\n",
    "# ÐžÑ†ÐµÐ½ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸ (ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ Ñ‚ÐµÑÑ‚Ð¾Ð²Ð°Ñ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ°)\n",
    "time_start = time.time()\n",
    "if formatted_test:\n",
    "    metrics = trainer_blank_empty.evaluate(formatted_test)\n",
    "    print(\"\\nÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð½Ð° Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð¹ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐµ:\")\n",
    "    print(f\"Precision: {metrics['precision']:.2f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.2f}\")\n",
    "    print(f\"F1-score: {metrics['f1_score']:.2f}\")\n",
    "else:\n",
    "    print(\"\\nÐ¢ÐµÑÑ‚Ð¾Ð²Ð°Ñ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ° Ð½Ðµ Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð°, Ð¾Ñ†ÐµÐ½ÐºÐ° Ð½Ðµ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð°\")\n",
    "print('Inference time: ', time.time() - time_start, ' c')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d6639620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:  122.83794498443604  c\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a5a5c345934b48983eaf029370934f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ðŸ” ÐžÑ†ÐµÐ½ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸:   0%|          | 0/879 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š ÐŸÐ¾Ð´Ñ€Ð¾Ð±Ð½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸:\n",
      "Ð¢Ð¸Ð¿                  Precision  Recall     F1         ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ° \n",
      "------------------------------------------------------------\n",
      "length               0.965      0.953      0.959      1236      \n",
      "tehnology            0.977      0.977      0.977      1017      \n",
      "product              0.994      0.991      0.993      4421      \n",
      "thickness            0.991      0.989      0.990      2812      \n",
      "color                0.960      0.960      0.960      100       \n",
      "coating              0.970      0.959      0.965      171       \n",
      "mark_steal           0.980      0.979      0.980      2724      \n",
      "material             0.980      0.992      0.986      1940      \n",
      "mark_steel_aisi      0.988      0.988      0.988      603       \n",
      "width                0.967      0.975      0.971      1869      \n",
      "type                 0.982      0.989      0.985      1862      \n",
      "mark                 0.915      0.933      0.924      403       \n",
      "height               0.942      0.921      0.931      579       \n",
      "form                 0.995      0.978      0.986      224       \n",
      "standart_gost        0.986      0.990      0.988      1525      \n",
      "manufacturer         0.933      0.947      0.940      132       \n",
      "country              0.958      0.920      0.939      25        \n",
      "standart_en          0.981      0.990      0.986      310       \n",
      "package              0.967      0.967      0.967      30        \n",
      "inner_diameter       0.975      0.982      0.978      1460      \n",
      "purpose              0.947      0.857      0.900      42        \n",
      "height_big           0.898      0.934      0.916      198       \n",
      "standart_tu          1.000      1.000      1.000      84        \n",
      "outer_diameter       0.971      0.948      0.959      524       \n",
      "strength_class       0.966      0.911      0.938      124       \n",
      "strength_class_old   0.905      0.987      0.944      77        \n",
      "height_small         1.000      0.111      0.200      9         \n",
      "precision            1.000      1.000      1.000      40        \n",
      "\n",
      "ðŸ” Ð˜Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ (micro-average):\n",
      "Precision: 0.979\n",
      "Recall: 0.979\n",
      "F1-score: 0.979\n",
      "Inference time:  8.277688264846802  c\n",
      "ÐœÐ°ÐºÑ€Ð¾-ÑƒÑÑ€ÐµÐ´Ð½ÐµÐ½Ð½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ (Ð²ÑÐµ ÐºÐ»Ð°ÑÑÑ‹ Ñ€Ð°Ð²Ð½Ñ‹):\n",
      "Macro-Precision: 0.9676\n",
      "Macro-Recall: 0.9332\n",
      "Macro-F1: 0.9375\n",
      "\n",
      "Ð’Ð·Ð²ÐµÑˆÐµÐ½Ð½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ (ÑƒÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÑŽÑ‚ Ñ€Ð°Ð·Ð¼ÐµÑ€ ÐºÐ»Ð°ÑÑÐ¾Ð²):\n",
      "Weighted Precision: 0.9790\n",
      "Weighted Recall: 0.9793\n",
      "Weighted F1: 0.9790\n",
      "\n",
      "ÐœÐ¸ÐºÑ€Ð¾-ÑƒÑÑ€ÐµÐ´Ð½ÐµÐ½Ð½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸:\n",
      "Micro-Precision: 0.9790\n",
      "Micro-Recall: 0.9793\n",
      "Micro-F1: 0.9790\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print('Train time: ', time.time() - time_start, ' c')\n",
    "# ÐžÑ†ÐµÐ½ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸ (ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ Ñ‚ÐµÑÑ‚Ð¾Ð²Ð°Ñ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ°)\n",
    "time_start = time.time()\n",
    "if formatted_test:\n",
    "    metrics = trainer_blank_empty.evaluate(formatted_test)\n",
    "print('Inference time: ', time.time() - time_start, ' c')    \n",
    "\n",
    "# Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ DataFrame Ð¸ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€ÑƒÐµÐ¼ ÐºÐ»Ð°ÑÑÑ‹ Ð±ÐµÐ· Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¸\n",
    "df = pd.DataFrame.from_dict(metrics, orient='index')\n",
    "#df = df[df['support'] > 0]  # Ð˜Ð³Ð½Ð¾Ñ€Ð¸Ñ€ÑƒÐµÐ¼ ÐºÐ»Ð°ÑÑÑ‹ Ñ support=0\n",
    "\n",
    "# 1. ÐœÐ°ÐºÑ€Ð¾-ÑƒÑÑ€ÐµÐ´Ð½ÐµÐ½Ð½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ (Ð²ÑÐµ ÐºÐ»Ð°ÑÑÑ‹ Ñ€Ð°Ð²Ð½Ð¾Ð·Ð½Ð°Ñ‡Ð½Ñ‹)\n",
    "macro_precision = df['precision'].mean()\n",
    "macro_recall = df['recall'].mean()\n",
    "macro_f1 = df['f1'].mean()\n",
    "\n",
    "print(\"ÐœÐ°ÐºÑ€Ð¾-ÑƒÑÑ€ÐµÐ´Ð½ÐµÐ½Ð½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ (Ð²ÑÐµ ÐºÐ»Ð°ÑÑÑ‹ Ñ€Ð°Ð²Ð½Ñ‹):\")\n",
    "print(f\"Macro-Precision: {macro_precision:.4f}\")\n",
    "print(f\"Macro-Recall: {macro_recall:.4f}\")\n",
    "print(f\"Macro-F1: {macro_f1:.4f}\\n\")\n",
    "\n",
    "# 2. Ð’Ð·Ð²ÐµÑˆÐµÐ½Ð½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ (ÑƒÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÑŽÑ‚ Ñ€Ð°Ð·Ð¼ÐµÑ€ ÐºÐ»Ð°ÑÑÐ¾Ð²)\n",
    "total_support = df['support'].sum()\n",
    "weighted_precision = (df['precision'] * df['support']).sum() / total_support\n",
    "weighted_recall = (df['recall'] * df['support']).sum() / total_support\n",
    "weighted_f1 = (df['f1'] * df['support']).sum() / total_support\n",
    "\n",
    "print(\"Ð’Ð·Ð²ÐµÑˆÐµÐ½Ð½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ (ÑƒÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÑŽÑ‚ Ñ€Ð°Ð·Ð¼ÐµÑ€ ÐºÐ»Ð°ÑÑÐ¾Ð²):\")\n",
    "print(f\"Weighted Precision: {weighted_precision:.4f}\")\n",
    "print(f\"Weighted Recall: {weighted_recall:.4f}\")\n",
    "print(f\"Weighted F1: {weighted_f1:.4f}\\n\")\n",
    "\n",
    "# 3. ÐœÐ¸ÐºÑ€Ð¾-ÑƒÑÑ€ÐµÐ´Ð½ÐµÐ½Ð½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ (Ð°Ð»ÑŒÑ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ñ€Ð°ÑÑ‡ÐµÑ‚)\n",
    "micro_precision = weighted_precision  # Ð”Ð»Ñ classification report Ð¾Ð½Ð¸ ÑÐ¾Ð²Ð¿Ð°Ð´Ð°ÑŽÑ‚\n",
    "micro_recall = weighted_recall\n",
    "micro_f1 = weighted_f1\n",
    "\n",
    "print(\"ÐœÐ¸ÐºÑ€Ð¾-ÑƒÑÑ€ÐµÐ´Ð½ÐµÐ½Ð½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸:\")\n",
    "print(f\"Micro-Precision: {micro_precision:.4f}\")\n",
    "print(f\"Micro-Recall: {micro_recall:.4f}\")\n",
    "print(f\"Micro-F1: {micro_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0e7fd7-0c39-4139-9f50-75baa6a900df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda95157f3314f248a0063aefdc893fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ðŸ“¥ Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ…: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ð£ÑÐ¿ÐµÑˆÐ½Ð¾ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾ 2051 Ð·Ð°Ð¿Ð¸ÑÐµÐ¹\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9dcdda129742b08c380ad268aaa98a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ðŸ“¥ Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ…: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ð£ÑÐ¿ÐµÑˆÐ½Ð¾ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾ 879 Ð·Ð°Ð¿Ð¸ÑÐµÐ¹\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12cc51464dff40a3b5721f750c1406b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ðŸ”§ ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ…:   0%|          | 0/2051 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° Ð² ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ðµ: ÐÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ðµ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸: 117-121 Ð´Ð»Ñ Ñ‚ÐµÐºÑÑ‚Ð° Ð´Ð»Ð¸Ð½Ñ‹ 114. Ð¢ÐµÐºÑÑ‚: ''\n",
      "âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° Ð² ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ðµ: ÐÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ñ‹Ðµ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸: 262-267 Ð´Ð»Ñ Ñ‚ÐµÐºÑÑ‚Ð° Ð´Ð»Ð¸Ð½Ñ‹ 259. Ð¢ÐµÐºÑÑ‚: ''\n",
      "ðŸ”´ Ð’ÑÐµÐ³Ð¾ Ð¾ÑˆÐ¸Ð±Ð¾Ðº: 2 (Ð¸Ð· 2051)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4955738b0f624bcca2747db4dbddcea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ðŸ”§ ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ…:   0%|          | 0/879 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ GPU Ð½Ðµ Ð´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ CPU\n",
      "âœ… Ð¡Ð¾Ð·Ð´Ð°Ð½Ð° Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼ÐµÑ€Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ñ DeepPavlov/rubert-base-cased\n",
      "ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð¾Ð±ÑƒÑ‡Ð°ÑŽÑ‰Ð¸Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…: [('Ð»Ð¸ÑÑ‚ Ð½ÐµÑ€Ð¶Ð°Ð²ÐµÑŽÑ‰Ð¸Ð¹ 4 x 1500 x 3000 mm aisi 201 12Ñ…15Ð³9Ð½Ð´ Ð³ / Ðº Ð¼Ð°Ñ‚Ð¾Ð²Ñ‹Ð¹\\n\\n\\nÐ»Ð¸ÑÑ‚ Ð½ÐµÑ€Ð¶Ð°Ð²ÐµÑŽÑ‰Ð¸Ð¹ 8 x 1500 x 3000 mm aisi 201 12Ñ…15Ð³9Ð½Ð´ Ð³ / Ðº Ð¼Ð°Ñ‚Ð¾Ð²Ñ‹Ð¹\\n\\n\\nÐ»Ð¸ÑÑ‚ Ð½ÐµÑ€Ð¶Ð°Ð²ÐµÑŽÑ‰Ð¸Ð¹ 1.5 x 1000 x 2000 mm aisi 201 12Ñ…15Ð³9Ð½Ð´ Ñ… / Ðº ÑˆÐ»Ð¸Ñ„Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹\\n\\n\\nÐ»Ð¸ÑÑ‚ Ð½ÐµÑ€Ð¶Ð°Ð²ÐµÑŽÑ‰Ð¸Ð¹ 2 x 1000 x 2000 mm aisi 201 12Ñ…15Ð³9Ð½Ð´ Ð³ / Ðº Ð¿Ñ€Ð¾ÑÐµÑ‡Ð½Ð¾ - Ð²Ñ‹Ñ‚ÑÐ¶Ð½Ð¾Ð¹ Ð¿Ð²Ð»\\n\\n\\nÐ»Ð¸ÑÑ‚ Ð½ÐµÑ€Ð¶Ð°Ð²ÐµÑŽÑ‰Ð¸Ð¹ 4 x 1000 x 2000 mm aisi 201 12Ñ…15Ð³9Ð½Ð´ Ð³ / Ðº Ð¿Ñ€Ð¾ÑÐµÑ‡Ð½Ð¾ - Ð²Ñ‹Ñ‚ÑÐ¶Ð½Ð¾Ð¹ Ð¿Ð²Ð»', {'entities': [(0, 4, 'product'), (5, 16, 'material'), (17, 18, 'thickness'), (21, 25, 'width'), (28, 32, 'length'), (36, 44, 'mark_steel_aisi'), (45, 54, 'mark_steal'), (55, 60, 'tehnology'), (61, 68, 'color'), (71, 75, 'product'), (76, 87, 'material'), (88, 89, 'thickness'), (92, 96, 'width'), (99, 103, 'length'), (107, 115, 'mark_steel_aisi'), (116, 125, 'mark_steal'), (126, 131, 'tehnology'), (132, 139, 'color'), (142, 146, 'product'), (147, 158, 'material'), (159, 162, 'thickness'), (165, 169, 'width'), (172, 176, 'length'), (180, 188, 'mark_steel_aisi'), (189, 198, 'mark_steal'), (199, 204, 'tehnology'), (205, 216, 'coating'), (219, 223, 'product'), (224, 235, 'material'), (236, 237, 'thickness'), (240, 244, 'width'), (247, 251, 'length'), (255, 263, 'mark_steel_aisi'), (264, 273, 'mark_steal'), (274, 279, 'tehnology'), (280, 299, 'type'), (300, 303, 'mark'), (306, 310, 'product'), (311, 322, 'material'), (323, 324, 'thickness'), (327, 331, 'width'), (334, 338, 'length'), (342, 350, 'mark_steel_aisi'), (351, 360, 'mark_steal'), (361, 366, 'tehnology'), (367, 386, 'type'), (387, 390, 'mark')]})]\n",
      "ðŸ· Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ñ‹ Ð¼ÐµÑ‚ÐºÐ¸: ['coating', 'color', 'country', 'form', 'height', 'height_big', 'height_small', 'inner_diameter', 'length', 'manufacturer', 'mark', 'mark_steal', 'mark_steel_aisi', 'material', 'outer_diameter', 'package', 'precision', 'product', 'purpose', 'standart_en', 'standart_gost', 'standart_tu', 'strength_class', 'strength_class_old', 'tehnology', 'thickness', 'type', 'width']\n",
      "\n",
      "Ð Ð°Ð·Ð¼ÐµÑ€ Ð¾Ð±ÑƒÑ‡Ð°ÑŽÑ‰ÐµÐ¹ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ¸: 2049\n",
      "Ð Ð°Ð·Ð¼ÐµÑ€ Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð¹ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ¸: 879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cca332e427046da907fce62fcf70be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ð­Ð¿Ð¾Ñ…Ð° 1/10:   0%|          | 0/513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ð­Ð¿Ð¾Ñ…Ð° 1/10\n",
      "ðŸ“‰ Loss: 59980.936\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc7e96c4ef348a4b99869af303e86e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ð­Ð¿Ð¾Ñ…Ð° 2/10:   0%|          | 0/513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ð­Ð¿Ð¾Ñ…Ð° 2/10\n",
      "ðŸ“‰ Loss: 21648.147\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7775c699af6e422c98f02599acc815ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ð­Ð¿Ð¾Ñ…Ð° 3/10:   0%|          | 0/513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ð­Ð¿Ð¾Ñ…Ð° 3/10\n",
      "ðŸ“‰ Loss: 12628.520\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da538bca59f84833a5d324e053b566ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ð­Ð¿Ð¾Ñ…Ð° 4/10:   0%|          | 0/513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ð­Ð¿Ð¾Ñ…Ð° 4/10\n",
      "ðŸ“‰ Loss: 8729.204\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a395a7b8a1348c489f0e9612b58149c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ð­Ð¿Ð¾Ñ…Ð° 5/10:   0%|          | 0/513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ð­Ð¿Ð¾Ñ…Ð° 5/10\n",
      "ðŸ“‰ Loss: 6783.503\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93dd706a26064c189b7815a3f9a5dbba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ð­Ð¿Ð¾Ñ…Ð° 6/10:   0%|          | 0/513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ð­Ð¿Ð¾Ñ…Ð° 6/10\n",
      "ðŸ“‰ Loss: 5536.863\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "156d1506177148aa970df14253fd766f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ð­Ð¿Ð¾Ñ…Ð° 7/10:   0%|          | 0/513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ð­Ð¿Ð¾Ñ…Ð° 7/10\n",
      "ðŸ“‰ Loss: 4647.616\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1e213945e64bbc8fab6b4d2523fae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ð­Ð¿Ð¾Ñ…Ð° 8/10:   0%|          | 0/513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ð­Ð¿Ð¾Ñ…Ð° 8/10\n",
      "ðŸ“‰ Loss: 4039.089\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4565a22d4c4411082157aa1b688919c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ð­Ð¿Ð¾Ñ…Ð° 9/10:   0%|          | 0/513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ð­Ð¿Ð¾Ñ…Ð° 9/10\n",
      "ðŸ“‰ Loss: 3319.055\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985076d3840e40ba848a7a9ece8c540d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ð­Ð¿Ð¾Ñ…Ð° 10/10:   0%|          | 0/513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processor = DataProcessor()\n",
    "\n",
    "# Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ…\n",
    "train_data = processor.load_data(\"../../data/jsonl/dataset_jsonl_train.jsonl\")\n",
    "test_data = processor.load_data(\"../../data/jsonl/dataset_jsonl_test.jsonl\")\n",
    "\n",
    "# ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ\n",
    "formatted_train = processor.prepare_data(train_data)\n",
    "formatted_test = processor.prepare_data(test_data) if test_data else None\n",
    "\n",
    "time_start = time.time()\n",
    "# Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ñ‚Ñ€ÐµÐ½ÐµÑ€Ð°\n",
    "trainer_blank_empty = NERTrainer(\n",
    "    blank_language=\"ru\",\n",
    "    transformer_name=\"DeepPavlov/rubert-base-cased\"\n",
    ")\n",
    "\n",
    "# Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¼ÐµÑ‚Ð¾Ðº Ð”Ðž Ñ€Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸Ñ (Ñ‚ÐµÐ¿ÐµÑ€ÑŒ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²Ð»ÐµÐ½Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ)\n",
    "print(\"ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð¾Ð±ÑƒÑ‡Ð°ÑŽÑ‰Ð¸Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…:\", formatted_train[:1])  # Ð¿Ð¾ÐºÐ°Ð¶ÐµÐ¼ Ð¿ÐµÑ€Ð²Ñ‹Ð¹ Ð¿Ñ€Ð¸Ð¼ÐµÑ€ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸\n",
    "trainer_blank_empty.add_labels(formatted_train)\n",
    "\n",
    "print(f\"\\nÐ Ð°Ð·Ð¼ÐµÑ€ Ð¾Ð±ÑƒÑ‡Ð°ÑŽÑ‰ÐµÐ¹ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ¸: {len(formatted_train)}\")\n",
    "print(f\"Ð Ð°Ð·Ð¼ÐµÑ€ Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð¹ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ¸: {len(formatted_test) if formatted_test else 0}\")\n",
    "\n",
    "# ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ (ÑƒÐ²ÐµÐ»Ð¸Ñ‡Ð¸Ð¼ epochs Ð´Ð»Ñ Ð»ÑƒÑ‡ÑˆÐµÐ³Ð¾ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð°)\n",
    "trainer_blank_empty.train(\n",
    "    formatted_train, \n",
    "    epochs=10,\n",
    "    batch_size=16,  \n",
    "    save_path=r\"C:\\Users\\mezhonnyy\\Desktop\\Ð ÐµÑˆÐµÐ½Ð¸Ñ\\NER\\model\\NER_final\\data\\jsonl\\model\"\n",
    ")\n",
    "print('Train time: ', time.time() - time_start, ' c')\n",
    "# ÐžÑ†ÐµÐ½ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸ (ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ Ñ‚ÐµÑÑ‚Ð¾Ð²Ð°Ñ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ°)\n",
    "time_start = time.time()\n",
    "if formatted_test:\n",
    "    metrics = trainer_blank_empty.evaluate(formatted_test)\n",
    "    print(\"\\nÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð½Ð° Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð¹ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐµ:\")\n",
    "    print(f\"Precision: {metrics['precision']:.2f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.2f}\")\n",
    "    print(f\"F1-score: {metrics['f1_score']:.2f}\")\n",
    "else:\n",
    "    print(\"\\nÐ¢ÐµÑÑ‚Ð¾Ð²Ð°Ñ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ° Ð½Ðµ Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð°, Ð¾Ñ†ÐµÐ½ÐºÐ° Ð½Ðµ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð°\")\n",
    "print('Inference time: ', time.time() - time_start, ' c')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a6743839-f2b7-4218-970a-25869be94aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ÐºÑƒÐ¿Ð¸Ñ‚ÑŒ', 'product', 0, 6),\n",
       " ('ÑˆÐµÑÑ‚Ð¸Ð³Ñ€Ð°Ð½Ð½Ð¸Ðº', 'product', 7, 19),\n",
       " ('ÐºÐ°Ð»Ð¸Ð±Ñ€', 'type', 20, 26),\n",
       " ('ÑÑ‚40x 27', 'mark_steal', 27, 35),\n",
       " ('Ð³Ð¾ÑÑ‚ 8560 - 78', 'standart_gost', 36, 50),\n",
       " ('4543 - 2016', 'standart_gost', 52, 63),\n",
       " ('95', 'width', 76, 78)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_blank.predict('ÐºÑƒÐ¿Ð¸Ñ‚ÑŒ ÑˆÐµÑÑ‚Ð¸Ð³Ñ€Ð°Ð½Ð½Ð¸Ðº ÐºÐ°Ð»Ð¸Ð±Ñ€ ÑÑ‚40x 27 Ð³Ð¾ÑÑ‚ 8560 - 78, 4543 - 2016 Ñ†ÐµÐ½Ð° 013568-95')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fc4399-8b0d-4fcf-81b7-46d4ba8f6d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_blank_empty.predict('ÐºÑƒÐ¿Ð¸Ñ‚ÑŒ ÑˆÐµÑÑ‚Ð¸Ð³Ñ€Ð°Ð½Ð½Ð¸Ðº ÐºÐ°Ð»Ð¸Ð±Ñ€ ÑÑ‚40x 27 Ð³Ð¾ÑÑ‚ 8560 - 78, 4543 - 2016 Ñ†ÐµÐ½Ð° 013568-95')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
