{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333ff255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from seqeval.metrics import classification_report as seqeval_report\n",
    "from typing import List, Union\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65393be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing all random seeds\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "set_seed(42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce727e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "def tokenizer(text):\n",
    "    tokens = []    \n",
    "    # RegEx\n",
    "    word_re = re.compile(r'''\n",
    "        \\w+[-\\w]*|      \n",
    "        [^\\w\\s]|         \n",
    "        \\d+\\.\\d+|        \n",
    "        \\d+/\\d+|        \n",
    "        \\d+              \n",
    "    ''', re.VERBOSE)\n",
    "    \n",
    "    for match in word_re.finditer(text):\n",
    "        tokens.append(match.group())\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc7703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "    def __init__(self, data, vocab, tag_encoder):\n",
    "        self.data = data\n",
    "        self.vocab = vocab\n",
    "        self.tag_encoder = tag_encoder\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.data[idx]\n",
    "        tokens = entry[\"tokens\"]\n",
    "        tags = entry[\"tags\"]\n",
    "        \n",
    "        word_ids = [self.vocab.get(token, 1) for token in tokens]\n",
    "        tag_ids = self.tag_encoder.transform(tags)\n",
    "        \n",
    "        return torch.tensor(word_ids, dtype=torch.long), torch.tensor(tag_ids, dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    words, tags = zip(*batch)\n",
    "    words_padded = pad_sequence(words, batch_first=True, padding_value=0)\n",
    "    tags_padded = pad_sequence(tags, batch_first=True, padding_value=-100)\n",
    "    return words_padded, tags_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21201ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniversalCNN_NER(nn.Module):\n",
    "    def __init__(self, \n",
    "                 vocab_size: int,\n",
    "                 num_tags: int,\n",
    "                 embedding_dim: int = 100,\n",
    "                 num_filters: int = 128,\n",
    "                 filter_sizes: Union[int, List[int]] = [3, 5, 7],\n",
    "                 use_lstm: bool = False,\n",
    "                 lstm_hidden: int = 256,\n",
    "                 bidirectional: bool = True,\n",
    "                 use_layernorm: bool = False,\n",
    "                 dropout: float = 0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        \n",
    "        if isinstance(filter_sizes, int):\n",
    "            filter_sizes = [filter_sizes]\n",
    "        self.num_conv_layers = len(filter_sizes)\n",
    "        \n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        in_channels = embedding_dim\n",
    "        \n",
    "        for i, fs in enumerate(filter_sizes):\n",
    "            self.conv_layers.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv1d(\n",
    "                        in_channels=in_channels,\n",
    "                        out_channels=num_filters,\n",
    "                        kernel_size=fs,\n",
    "                        padding=fs//2\n",
    "                    ),\n",
    "                    nn.GELU(),\n",
    "                    nn.Dropout(dropout)\n",
    "                )\n",
    "            )\n",
    "            in_channels = num_filters\n",
    "        \n",
    "        self.use_lstm = use_lstm\n",
    "        if use_lstm:\n",
    "            self.lstm = nn.LSTM(\n",
    "                input_size=num_filters,\n",
    "                hidden_size=lstm_hidden,\n",
    "                num_layers=1,\n",
    "                bidirectional=bidirectional,\n",
    "                batch_first=True\n",
    "            )\n",
    "            lstm_output_size = lstm_hidden * 2 if bidirectional else lstm_hidden\n",
    "        else:\n",
    "            lstm_output_size = num_filters\n",
    "        \n",
    "        self.use_layernorm = use_layernorm\n",
    "        if use_layernorm:\n",
    "            self.layernorm = nn.LayerNorm(lstm_output_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(lstm_output_size, num_tags)\n",
    "        \n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for layer in self.conv_layers:\n",
    "            nn.init.kaiming_normal_(layer[0].weight, mode='fan_out', nonlinearity='relu')\n",
    "            nn.init.constant_(layer[0].bias, 0)\n",
    "        \n",
    "        if hasattr(self, 'lstm'):\n",
    "            for name, param in self.lstm.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    nn.init.xavier_normal_(param)\n",
    "                else:\n",
    "                    nn.init.constant_(param, 0)\n",
    "        \n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  \n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        # Применение CNN слоев\n",
    "        for conv in self.conv_layers:\n",
    "            x = conv(x)\n",
    "        \n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        if self.use_lstm:\n",
    "            x, _ = self.lstm(x)\n",
    "        \n",
    "        if self.use_layernorm:\n",
    "            x = self.layernorm(x)\n",
    "        \n",
    "        return self.fc(self.dropout(x))\n",
    "    \n",
    "# Train\n",
    "def train_model(model, dataloader, num_tags, epochs=20, lr=1e-3, model_save_path='best_model.pt'):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    #criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        epoch_loss = 0.0\n",
    "        model.train()\n",
    "        \n",
    "        for words, tags in dataloader:\n",
    "            words = words.to(device)\n",
    "            tags = tags.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = model(words)\n",
    "            \n",
    "            # Правильный reshape\n",
    "            outputs = outputs.reshape(-1, num_tags)\n",
    "            tags = tags.reshape(-1) \n",
    "            \n",
    "            loss = criterion(outputs, tags)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        \n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        \n",
    "        print(f'\\nEpoch {epoch+1}/{epochs} | Avg Loss: {avg_loss:.4f}')\n",
    "    return model\n",
    "\n",
    "# Predicted\n",
    "def predict(model, sentence, vocab, tag_encoder):\n",
    "    model.eval()\n",
    "    word_ids = [vocab.get(word, 1) for word in sentence]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(torch.tensor([word_ids]))\n",
    "        _, predicted = torch.max(outputs, 2)\n",
    "    \n",
    "    predicted_tags = tag_encoder.inverse_transform(predicted.squeeze().numpy())\n",
    "    \n",
    "    entities = []\n",
    "    current_entity = None\n",
    "    start_idx = 0\n",
    "    \n",
    "    for i, (word, tag) in enumerate(zip(sentence, predicted_tags)):\n",
    "        if tag.startswith('B-'):\n",
    "            if current_entity is not None:\n",
    "                entities.append((start_idx, i, current_entity))\n",
    "            current_entity = tag[2:]\n",
    "            start_idx = i\n",
    "        elif tag == 'O' and current_entity is not None:\n",
    "            entities.append((start_idx, i, current_entity))\n",
    "            current_entity = None\n",
    "    \n",
    "    if current_entity is not None:\n",
    "        entities.append((start_idx, len(sentence), current_entity))\n",
    "    \n",
    "    # Return results\n",
    "    for start, end, entity_type in entities:\n",
    "        entity_text = ' '.join(sentence[start:end])\n",
    "        print(f\"{entity_text} -> {entity_type}\")\n",
    "    \n",
    "    return predicted_tags\n",
    "\n",
    "\n",
    "# 6. Предсказание\n",
    "def evaluate_model(model, test_data, vocab, tag_encoder):\n",
    "    model.eval()\n",
    "    all_true_tags = []\n",
    "    all_pred_tags = []\n",
    "    \n",
    "    for entry in test_data:\n",
    "        tokens = entry[\"tokens\"]\n",
    "        true_tags = entry[\"tags\"]\n",
    "        \n",
    "        word_ids = [vocab.get(word, 1) for word in tokens]\n",
    "        with torch.no_grad():\n",
    "            outputs = model(torch.tensor([word_ids]))\n",
    "            _, predicted = torch.max(outputs, 2)\n",
    "        \n",
    "        pred_tags = tag_encoder.inverse_transform(predicted.squeeze().numpy())\n",
    "        \n",
    "        all_true_tags.append(true_tags)\n",
    "        all_pred_tags.append(pred_tags.tolist())\n",
    "    \n",
    "    # Entity-level\n",
    "    entity_report = seqeval_report(all_true_tags, all_pred_tags, zero_division=0)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    entity_types = set(tag[2:] for tags in all_true_tags for tag in tags if tag != 'O')\n",
    "    entity_metrics = {}\n",
    "    \n",
    "    for entity in entity_types:\n",
    "        tp = 0  # True Positives\n",
    "        fp = 0  # False Positives\n",
    "        fn = 0  # False Negatives\n",
    "        \n",
    "        for true_seq, pred_seq in zip(all_true_tags, all_pred_tags):\n",
    "            true_entities = get_entities(true_seq)\n",
    "            pred_entities = get_entities(pred_seq)\n",
    "            \n",
    "            true_set = set((start, end) for (start, end, e_type) in true_entities if e_type == entity)\n",
    "            pred_set = set((start, end) for (start, end, e_type) in pred_entities if e_type == entity)\n",
    "            \n",
    "            tp += len(true_set & pred_set)\n",
    "            fp += len(pred_set - true_set)\n",
    "            fn += len(true_set - pred_set)\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        entity_metrics[entity] = {\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'support': tp + fn\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        'entity_level': entity_report,\n",
    "        'entity_metrics': entity_metrics\n",
    "    }\n",
    "\n",
    "def get_entities(tag_sequence):\n",
    "    entities = []\n",
    "    current_entity = None\n",
    "    start_idx = 0\n",
    "    \n",
    "    for i, tag in enumerate(tag_sequence):\n",
    "        if tag.startswith('B-'):\n",
    "            if current_entity is not None:\n",
    "                entities.append((start_idx, i, current_entity))\n",
    "            current_entity = tag[2:]\n",
    "            start_idx = i\n",
    "        elif tag == 'O' and current_entity is not None:\n",
    "            entities.append((start_idx, i, current_entity))\n",
    "            current_entity = None\n",
    "    \n",
    "    if current_entity is not None:\n",
    "        entities.append((start_idx, len(tag_sequence), current_entity))\n",
    "    \n",
    "    return entities    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa5b1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "with open(r\"..\\..\\data\\raw\\dataset_train.json\", 'r', encoding='utf-8') as fp:\n",
    "    #print(fp.read(4544900))\n",
    "    sample_data_train = json.load(fp)\n",
    "print(len(sample_data_train))\n",
    "\n",
    "with open(r\"..\\..\\data\\raw\\dataset_test.json\", 'r', encoding='utf-8') as fp:\n",
    "    sample_data_test = json.load(fp)\n",
    "print(len(sample_data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2e8193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary\n",
    "word_counts = defaultdict(int)\n",
    "all_tags = []\n",
    "\n",
    "for entry in sample_data_train:\n",
    "    for token in entry[\"tokens\"]:\n",
    "        word_counts[token] += 1\n",
    "    all_tags.extend(entry[\"tags\"])\n",
    "\n",
    "vocab = {word: i+2 for i, word in enumerate(word_counts)}  # 0 для padding, 1 для UNK\n",
    "vocab_size = len(vocab) + 2\n",
    "\n",
    "tag_encoder = LabelEncoder()\n",
    "tag_encoder.fit(all_tags)\n",
    "num_tags = len(tag_encoder.classes_)\n",
    "\n",
    "dataset = NERDataset(sample_data_train, vocab, tag_encoder)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed78bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train simple CNN (1 layer)\n",
    "time_start = time.time()\n",
    "model = UniversalCNN_NER(\n",
    "    vocab_size=10000,\n",
    "    num_tags=len(tag_encoder.classes_),\n",
    "    filter_sizes=3,\n",
    "    use_lstm=False \n",
    ")\n",
    "\n",
    "trained_model = train_model(\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    num_tags=len(tag_encoder.classes_),\n",
    "    epochs=20,\n",
    "    lr=1e-3\n",
    ")\n",
    "\n",
    "print('Time train: ', time.time() - time_start, 'c')\n",
    "\n",
    "time_start = time.time()\n",
    "metrics = evaluate_model(model, sample_data_test, vocab, tag_encoder)\n",
    "\n",
    "print(\"\\n=== Entity-level Metrics ===\")\n",
    "print(metrics['entity_level'])\n",
    "\n",
    "print(\"\\n=== Per-entity Metrics ===\")\n",
    "for entity, scores in metrics['entity_metrics'].items():\n",
    "    print(f\"{entity}:\")\n",
    "    print(f\"  Precision: {scores['precision']:.4f}\")\n",
    "    print(f\"  Recall:    {scores['recall']:.4f}\")\n",
    "    print(f\"  F1-score:  {scores['f1']:.4f}\")\n",
    "    print(f\"  Support:   {scores['support']}\")\n",
    "print(\"Time inference: \", time.time() - time_start, ' c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e680c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train simple CNN (2 layer)\n",
    "time_start = time.time()\n",
    "model = UniversalCNN_NER(\n",
    "    vocab_size=10000,\n",
    "    num_tags=len(tag_encoder.classes_),\n",
    "    filter_sizes=[3, 5],\n",
    "    num_filters=256,\n",
    "    use_lstm=False \n",
    ")\n",
    "\n",
    "trained_model = train_model(\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    num_tags=len(tag_encoder.classes_),\n",
    "    epochs=20,\n",
    "    lr=1e-3\n",
    ")\n",
    "\n",
    "print('Time train: ', time.time() - time_start, 'c')\n",
    "\n",
    "time_start = time.time()\n",
    "metrics = evaluate_model(model, sample_data_test, vocab, tag_encoder)\n",
    "\n",
    "print(\"\\n=== Entity-level Metrics ===\")\n",
    "print(metrics['entity_level'])\n",
    "\n",
    "print(\"\\n=== Per-entity Metrics ===\")\n",
    "for entity, scores in metrics['entity_metrics'].items():\n",
    "    print(f\"{entity}:\")\n",
    "    print(f\"  Precision: {scores['precision']:.4f}\")\n",
    "    print(f\"  Recall:    {scores['recall']:.4f}\")\n",
    "    print(f\"  F1-score:  {scores['f1']:.4f}\")\n",
    "    print(f\"  Support:   {scores['support']}\")\n",
    "print(\"Time inference: \", time.time() - time_start, ' c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de3b3c6a-59b1-4e59-8407-4ff6fad89936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.1109\n",
      "\n",
      "Epoch 4/20 | Avg Loss: 0.0839\n",
      "Epoch 5, Loss: 0.0659\n",
      "\n",
      "Epoch 5/20 | Avg Loss: 0.0734\n",
      "Epoch 6, Loss: 0.0252\n",
      "\n",
      "Epoch 6/20 | Avg Loss: 0.0591\n",
      "Epoch 7, Loss: 0.0007\n",
      "\n",
      "Epoch 7/20 | Avg Loss: 0.0565\n",
      "Epoch 8, Loss: 0.0837\n",
      "\n",
      "Epoch 8/20 | Avg Loss: 0.0534\n",
      "Epoch 9, Loss: 0.0158\n",
      "\n",
      "Epoch 9/20 | Avg Loss: 0.0509\n",
      "Epoch 10, Loss: 0.0344\n",
      "\n",
      "Epoch 10/20 | Avg Loss: 0.0496\n",
      "Epoch 11, Loss: 0.0014\n",
      "\n",
      "Epoch 11/20 | Avg Loss: 0.0476\n",
      "Epoch 12, Loss: 0.0014\n",
      "\n",
      "Epoch 12/20 | Avg Loss: 0.0463\n",
      "Epoch 13, Loss: 0.0922\n",
      "\n",
      "Epoch 13/20 | Avg Loss: 0.0397\n",
      "Epoch 14, Loss: 0.0374\n",
      "\n",
      "Epoch 14/20 | Avg Loss: 0.0412\n",
      "Epoch 15, Loss: 0.0252\n",
      "\n",
      "Epoch 15/20 | Avg Loss: 0.0380\n",
      "Epoch 16, Loss: 0.1932\n",
      "\n",
      "Epoch 16/20 | Avg Loss: 0.0384\n",
      "Epoch 17, Loss: 0.1215\n",
      "\n",
      "Epoch 17/20 | Avg Loss: 0.0411\n",
      "Epoch 18, Loss: 0.1632\n",
      "\n",
      "Epoch 18/20 | Avg Loss: 0.0394\n",
      "Epoch 19, Loss: 0.0187\n",
      "\n",
      "Epoch 19/20 | Avg Loss: 0.0366\n",
      "Epoch 20, Loss: 0.0004\n",
      "\n",
      "Epoch 20/20 | Avg Loss: 0.0373\n",
      "Time train:  207.43672037124634 c\n",
      "\n",
      "=== Entity-level Metrics ===\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           coating       0.99      0.91      0.95       203\n",
      "             color       0.96      0.93      0.95       107\n",
      "           country       0.86      0.76      0.81        25\n",
      "              form       0.98      0.95      0.96       231\n",
      "            height       0.97      0.94      0.96       581\n",
      "        height_big       0.99      0.95      0.97       198\n",
      "      height_small       1.00      0.73      0.84        11\n",
      "    inner_diameter       0.98      0.98      0.98      1616\n",
      "            length       0.95      0.96      0.95      1714\n",
      "      manufacturer       0.96      0.87      0.91       153\n",
      "              mark       0.97      0.96      0.96      1043\n",
      "        mark_steal       0.99      0.99      0.99     10763\n",
      "   mark_steel_aisi       0.99      0.99      0.99      1333\n",
      "          material       0.99      0.98      0.98      2073\n",
      "    outer_diameter       0.96      0.96      0.96       604\n",
      "           package       0.96      0.90      0.93        30\n",
      "         precision       1.00      1.00      1.00        89\n",
      "           product       0.99      0.99      0.99      4783\n",
      "           purpose       1.00      0.64      0.78        50\n",
      "       standart_en       0.99      0.99      0.99       915\n",
      "     standart_gost       1.00      0.99      0.99      5271\n",
      "       standart_tu       0.94      1.00      0.97       364\n",
      "    strength_class       1.00      0.97      0.99       305\n",
      "strength_class_old       0.97      1.00      0.98       190\n",
      "         tehnology       0.99      0.99      0.99      1789\n",
      "         thickness       0.98      0.99      0.99      4632\n",
      "              type       0.99      0.98      0.99      1932\n",
      "             width       0.96      0.97      0.97      2020\n",
      "\n",
      "         micro avg       0.98      0.98      0.98     43025\n",
      "         macro avg       0.97      0.94      0.95     43025\n",
      "      weighted avg       0.98      0.98      0.98     43025\n",
      "\n",
      "\n",
      "=== Per-entity Metrics ===\n",
      "product:\n",
      "  Precision: 0.9896\n",
      "  Recall:    0.9916\n",
      "  F1-score:  0.9906\n",
      "  Support:   4783\n",
      "precision:\n",
      "  Precision: 1.0000\n",
      "  Recall:    1.0000\n",
      "  F1-score:  1.0000\n",
      "  Support:   89\n",
      "coating:\n",
      "  Precision: 0.9892\n",
      "  Recall:    0.9064\n",
      "  F1-score:  0.9460\n",
      "  Support:   203\n",
      "tehnology:\n",
      "  Precision: 0.9860\n",
      "  Recall:    0.9860\n",
      "  F1-score:  0.9860\n",
      "  Support:   1789\n",
      "strength_class:\n",
      "  Precision: 0.9966\n",
      "  Recall:    0.9738\n",
      "  F1-score:  0.9851\n",
      "  Support:   305\n",
      "package:\n",
      "  Precision: 0.9643\n",
      "  Recall:    0.9000\n",
      "  F1-score:  0.9310\n",
      "  Support:   30\n",
      "width:\n",
      "  Precision: 0.9649\n",
      "  Recall:    0.9653\n",
      "  F1-score:  0.9651\n",
      "  Support:   2020\n",
      "height_big:\n",
      "  Precision: 0.9895\n",
      "  Recall:    0.9495\n",
      "  F1-score:  0.9691\n",
      "  Support:   198\n",
      "color:\n",
      "  Precision: 0.9615\n",
      "  Recall:    0.9346\n",
      "  F1-score:  0.9479\n",
      "  Support:   107\n",
      "standart_en:\n",
      "  Precision: 0.9912\n",
      "  Recall:    0.9902\n",
      "  F1-score:  0.9907\n",
      "  Support:   915\n",
      "country:\n",
      "  Precision: 0.8636\n",
      "  Recall:    0.7600\n",
      "  F1-score:  0.8085\n",
      "  Support:   25\n",
      "inner_diameter:\n",
      "  Precision: 0.9772\n",
      "  Recall:    0.9808\n",
      "  F1-score:  0.9790\n",
      "  Support:   1616\n",
      "mark_steal:\n",
      "  Precision: 0.9897\n",
      "  Recall:    0.9918\n",
      "  F1-score:  0.9908\n",
      "  Support:   10763\n",
      "form:\n",
      "  Precision: 0.9778\n",
      "  Recall:    0.9524\n",
      "  F1-score:  0.9649\n",
      "  Support:   231\n",
      "length:\n",
      "  Precision: 0.9471\n",
      "  Recall:    0.9615\n",
      "  F1-score:  0.9543\n",
      "  Support:   1714\n",
      "purpose:\n",
      "  Precision: 1.0000\n",
      "  Recall:    0.6400\n",
      "  F1-score:  0.7805\n",
      "  Support:   50\n",
      "outer_diameter:\n",
      "  Precision: 0.9604\n",
      "  Recall:    0.9636\n",
      "  F1-score:  0.9620\n",
      "  Support:   604\n",
      "manufacturer:\n",
      "  Precision: 0.9568\n",
      "  Recall:    0.8693\n",
      "  F1-score:  0.9110\n",
      "  Support:   153\n",
      "mark:\n",
      "  Precision: 0.9727\n",
      "  Recall:    0.9559\n",
      "  F1-score:  0.9642\n",
      "  Support:   1043\n",
      "mark_steel_aisi:\n",
      "  Precision: 0.9902\n",
      "  Recall:    0.9895\n",
      "  F1-score:  0.9899\n",
      "  Support:   1333\n",
      "height_small:\n",
      "  Precision: 1.0000\n",
      "  Recall:    0.7273\n",
      "  F1-score:  0.8421\n",
      "  Support:   11\n",
      "strength_class_old:\n",
      "  Precision: 0.9694\n",
      "  Recall:    1.0000\n",
      "  F1-score:  0.9845\n",
      "  Support:   190\n",
      "standart_gost:\n",
      "  Precision: 0.9958\n",
      "  Recall:    0.9935\n",
      "  F1-score:  0.9947\n",
      "  Support:   5271\n",
      "material:\n",
      "  Precision: 0.9850\n",
      "  Recall:    0.9846\n",
      "  F1-score:  0.9848\n",
      "  Support:   2073\n",
      "standart_tu:\n",
      "  Precision: 0.9380\n",
      "  Recall:    0.9973\n",
      "  F1-score:  0.9667\n",
      "  Support:   364\n",
      "height:\n",
      "  Precision: 0.9715\n",
      "  Recall:    0.9398\n",
      "  F1-score:  0.9554\n",
      "  Support:   581\n",
      "type:\n",
      "  Precision: 0.9875\n",
      "  Recall:    0.9850\n",
      "  F1-score:  0.9863\n",
      "  Support:   1932\n",
      "thickness:\n",
      "  Precision: 0.9839\n",
      "  Recall:    0.9911\n",
      "  F1-score:  0.9875\n",
      "  Support:   4632\n",
      "Time inference:  2.593857526779175  c\n"
     ]
    }
   ],
   "source": [
    "# Train simple CNN (3 layer)\n",
    "time_start = time.time()\n",
    "model = UniversalCNN_NER(\n",
    "    vocab_size=10000,\n",
    "    num_tags=len(tag_encoder.classes_),\n",
    "    filter_sizes=[3, 5, 7],\n",
    "    num_filters=256,\n",
    "    use_lstm=False \n",
    ")\n",
    "\n",
    "trained_model = train_model(\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    num_tags=len(tag_encoder.classes_),\n",
    "    epochs=20,\n",
    "    lr=1e-3\n",
    ")\n",
    "\n",
    "print('Time train: ', time.time() - time_start, 'c')\n",
    "\n",
    "time_start = time.time()\n",
    "metrics = evaluate_model(model, sample_data_test, vocab, tag_encoder)\n",
    "\n",
    "print(\"\\n=== Entity-level Metrics ===\")\n",
    "print(metrics['entity_level'])\n",
    "\n",
    "print(\"\\n=== Per-entity Metrics ===\")\n",
    "for entity, scores in metrics['entity_metrics'].items():\n",
    "    print(f\"{entity}:\")\n",
    "    print(f\"  Precision: {scores['precision']:.4f}\")\n",
    "    print(f\"  Recall:    {scores['recall']:.4f}\")\n",
    "    print(f\"  F1-score:  {scores['f1']:.4f}\")\n",
    "    print(f\"  Support:   {scores['support']}\")\n",
    "print(\"Time inference: \", time.time() - time_start, ' c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1deddd80-abe7-47d5-a922-6a4ce5f25dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.1978\n",
      "\n",
      "Epoch 1/20 | Avg Loss: 0.6642\n",
      "Epoch 2, Loss: 0.0731\n",
      "\n",
      "Epoch 2/20 | Avg Loss: 0.2388\n",
      "Epoch 3, Loss: 0.1725\n",
      "\n",
      "Epoch 3/20 | Avg Loss: 0.1592\n",
      "Epoch 4, Loss: 0.0135\n",
      "\n",
      "Epoch 4/20 | Avg Loss: 0.1275\n",
      "Epoch 5, Loss: 0.1317\n",
      "\n",
      "Epoch 5/20 | Avg Loss: 0.1049\n",
      "Epoch 6, Loss: 0.0218\n",
      "\n",
      "Epoch 6/20 | Avg Loss: 0.0952\n",
      "Epoch 7, Loss: 0.1287\n",
      "\n",
      "Epoch 7/20 | Avg Loss: 0.0863\n",
      "Epoch 8, Loss: 0.0008\n",
      "\n",
      "Epoch 8/20 | Avg Loss: 0.0804\n",
      "Epoch 9, Loss: 0.1102\n",
      "\n",
      "Epoch 9/20 | Avg Loss: 0.0785\n",
      "Epoch 10, Loss: 0.2032\n",
      "\n",
      "Epoch 10/20 | Avg Loss: 0.0737\n",
      "Epoch 11, Loss: 0.0162\n",
      "\n",
      "Epoch 11/20 | Avg Loss: 0.0680\n",
      "Epoch 12, Loss: 0.0502\n",
      "\n",
      "Epoch 12/20 | Avg Loss: 0.0692\n",
      "Epoch 13, Loss: 0.0225\n",
      "\n",
      "Epoch 13/20 | Avg Loss: 0.0672\n",
      "Epoch 14, Loss: 0.0015\n",
      "\n",
      "Epoch 14/20 | Avg Loss: 0.0650\n",
      "Epoch 15, Loss: 0.0967\n",
      "\n",
      "Epoch 15/20 | Avg Loss: 0.0600\n",
      "Epoch 16, Loss: 0.2870\n",
      "\n",
      "Epoch 16/20 | Avg Loss: 0.0605\n",
      "Epoch 17, Loss: 0.1219\n",
      "\n",
      "Epoch 17/20 | Avg Loss: 0.0633\n",
      "Epoch 18, Loss: 0.1211\n",
      "\n",
      "Epoch 18/20 | Avg Loss: 0.0562\n",
      "Epoch 19, Loss: 0.0261\n",
      "\n",
      "Epoch 19/20 | Avg Loss: 0.0564\n",
      "Epoch 20, Loss: 0.0246\n",
      "\n",
      "Epoch 20/20 | Avg Loss: 0.0560\n",
      "Time train:  239.5668923854828 c\n",
      "\n",
      "=== Entity-level Metrics ===\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           coating       0.99      0.87      0.93       203\n",
      "             color       0.93      0.93      0.93       107\n",
      "           country       0.77      0.80      0.78        25\n",
      "              form       0.89      0.94      0.92       231\n",
      "            height       0.97      0.95      0.96       581\n",
      "        height_big       1.00      0.95      0.97       198\n",
      "      height_small       1.00      0.73      0.84        11\n",
      "    inner_diameter       0.98      0.98      0.98      1616\n",
      "            length       0.96      0.96      0.96      1714\n",
      "      manufacturer       0.65      0.87      0.75       153\n",
      "              mark       0.97      0.95      0.96      1043\n",
      "        mark_steal       0.98      0.99      0.99     10763\n",
      "   mark_steel_aisi       0.99      1.00      0.99      1333\n",
      "          material       0.99      0.98      0.98      2073\n",
      "    outer_diameter       0.96      0.97      0.96       604\n",
      "           package       0.92      0.77      0.84        30\n",
      "         precision       1.00      1.00      1.00        89\n",
      "           product       0.99      0.99      0.99      4783\n",
      "           purpose       0.90      0.56      0.69        50\n",
      "       standart_en       0.99      0.99      0.99       915\n",
      "     standart_gost       0.98      1.00      0.99      5271\n",
      "       standart_tu       0.95      0.99      0.97       364\n",
      "    strength_class       0.99      0.97      0.98       305\n",
      "strength_class_old       0.92      1.00      0.96       190\n",
      "         tehnology       0.99      0.98      0.98      1789\n",
      "         thickness       0.99      0.99      0.99      4632\n",
      "              type       0.99      0.97      0.98      1932\n",
      "             width       0.97      0.97      0.97      2020\n",
      "\n",
      "         micro avg       0.98      0.98      0.98     43025\n",
      "         macro avg       0.95      0.93      0.94     43025\n",
      "      weighted avg       0.98      0.98      0.98     43025\n",
      "\n",
      "\n",
      "=== Per-entity Metrics ===\n",
      "product:\n",
      "  Precision: 0.9935\n",
      "  Recall:    0.9887\n",
      "  F1-score:  0.9911\n",
      "  Support:   4783\n",
      "precision:\n",
      "  Precision: 1.0000\n",
      "  Recall:    1.0000\n",
      "  F1-score:  1.0000\n",
      "  Support:   89\n",
      "coating:\n",
      "  Precision: 0.9888\n",
      "  Recall:    0.8719\n",
      "  F1-score:  0.9267\n",
      "  Support:   203\n",
      "tehnology:\n",
      "  Precision: 0.9904\n",
      "  Recall:    0.9754\n",
      "  F1-score:  0.9828\n",
      "  Support:   1789\n",
      "strength_class:\n",
      "  Precision: 0.9933\n",
      "  Recall:    0.9738\n",
      "  F1-score:  0.9834\n",
      "  Support:   305\n",
      "package:\n",
      "  Precision: 0.9200\n",
      "  Recall:    0.7667\n",
      "  F1-score:  0.8364\n",
      "  Support:   30\n",
      "width:\n",
      "  Precision: 0.9708\n",
      "  Recall:    0.9698\n",
      "  F1-score:  0.9703\n",
      "  Support:   2020\n",
      "height_big:\n",
      "  Precision: 1.0000\n",
      "  Recall:    0.9495\n",
      "  F1-score:  0.9741\n",
      "  Support:   198\n",
      "color:\n",
      "  Precision: 0.9252\n",
      "  Recall:    0.9252\n",
      "  F1-score:  0.9252\n",
      "  Support:   107\n",
      "standart_en:\n",
      "  Precision: 0.9913\n",
      "  Recall:    0.9945\n",
      "  F1-score:  0.9929\n",
      "  Support:   915\n",
      "country:\n",
      "  Precision: 0.7692\n",
      "  Recall:    0.8000\n",
      "  F1-score:  0.7843\n",
      "  Support:   25\n",
      "inner_diameter:\n",
      "  Precision: 0.9765\n",
      "  Recall:    0.9790\n",
      "  F1-score:  0.9778\n",
      "  Support:   1616\n",
      "mark_steal:\n",
      "  Precision: 0.9841\n",
      "  Recall:    0.9928\n",
      "  F1-score:  0.9884\n",
      "  Support:   10763\n",
      "form:\n",
      "  Precision: 0.8934\n",
      "  Recall:    0.9437\n",
      "  F1-score:  0.9179\n",
      "  Support:   231\n",
      "length:\n",
      "  Precision: 0.9612\n",
      "  Recall:    0.9551\n",
      "  F1-score:  0.9582\n",
      "  Support:   1714\n",
      "purpose:\n",
      "  Precision: 0.9032\n",
      "  Recall:    0.5600\n",
      "  F1-score:  0.6914\n",
      "  Support:   50\n",
      "outer_diameter:\n",
      "  Precision: 0.9589\n",
      "  Recall:    0.9652\n",
      "  F1-score:  0.9620\n",
      "  Support:   604\n",
      "manufacturer:\n",
      "  Precision: 0.6520\n",
      "  Recall:    0.8693\n",
      "  F1-score:  0.7451\n",
      "  Support:   153\n",
      "mark:\n",
      "  Precision: 0.9650\n",
      "  Recall:    0.9530\n",
      "  F1-score:  0.9590\n",
      "  Support:   1043\n",
      "mark_steel_aisi:\n",
      "  Precision: 0.9888\n",
      "  Recall:    0.9962\n",
      "  F1-score:  0.9925\n",
      "  Support:   1333\n",
      "height_small:\n",
      "  Precision: 1.0000\n",
      "  Recall:    0.7273\n",
      "  F1-score:  0.8421\n",
      "  Support:   11\n",
      "strength_class_old:\n",
      "  Precision: 0.9179\n",
      "  Recall:    1.0000\n",
      "  F1-score:  0.9572\n",
      "  Support:   190\n",
      "standart_gost:\n",
      "  Precision: 0.9831\n",
      "  Recall:    0.9956\n",
      "  F1-score:  0.9893\n",
      "  Support:   5271\n",
      "material:\n",
      "  Precision: 0.9859\n",
      "  Recall:    0.9768\n",
      "  F1-score:  0.9813\n",
      "  Support:   2073\n",
      "standart_tu:\n",
      "  Precision: 0.9526\n",
      "  Recall:    0.9945\n",
      "  F1-score:  0.9731\n",
      "  Support:   364\n",
      "height:\n",
      "  Precision: 0.9685\n",
      "  Recall:    0.9518\n",
      "  F1-score:  0.9601\n",
      "  Support:   581\n",
      "type:\n",
      "  Precision: 0.9926\n",
      "  Recall:    0.9741\n",
      "  F1-score:  0.9833\n",
      "  Support:   1932\n",
      "thickness:\n",
      "  Precision: 0.9880\n",
      "  Recall:    0.9920\n",
      "  F1-score:  0.9900\n",
      "  Support:   4632\n",
      "Time inference:  2.821796178817749  c\n"
     ]
    }
   ],
   "source": [
    "# Train simple CNN (4 layer)\n",
    "time_start = time.time()\n",
    "model = UniversalCNN_NER(\n",
    "    vocab_size=10000,\n",
    "    embedding_dim=50,\n",
    "    num_tags=len(tag_encoder.classes_),\n",
    "    filter_sizes=[3, 5, 5, 7],\n",
    "    num_filters=256,\n",
    "    use_lstm=False \n",
    ")\n",
    "\n",
    "trained_model = train_model(\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    num_tags=len(tag_encoder.classes_),\n",
    "    epochs=20,\n",
    "    lr=1e-3\n",
    ")\n",
    "\n",
    "print('Time train: ', time.time() - time_start, 'c')\n",
    "\n",
    "time_start = time.time()\n",
    "metrics = evaluate_model(model, sample_data_test, vocab, tag_encoder)\n",
    "\n",
    "print(\"\\n=== Entity-level Metrics ===\")\n",
    "print(metrics['entity_level'])\n",
    "\n",
    "print(\"\\n=== Per-entity Metrics ===\")\n",
    "for entity, scores in metrics['entity_metrics'].items():\n",
    "    print(f\"{entity}:\")\n",
    "    print(f\"  Precision: {scores['precision']:.4f}\")\n",
    "    print(f\"  Recall:    {scores['recall']:.4f}\")\n",
    "    print(f\"  F1-score:  {scores['f1']:.4f}\")\n",
    "    print(f\"  Support:   {scores['support']}\")\n",
    "print(\"Time inference: \", time.time() - time_start, ' c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ca17ea6f-1a86-4ed2-908e-e609b7bf0881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.1572\n",
      "\n",
      "Epoch 1/20 | Avg Loss: 0.6893\n",
      "Epoch 2, Loss: 0.0288\n",
      "\n",
      "Epoch 2/20 | Avg Loss: 0.2147\n",
      "Epoch 3, Loss: 0.0159\n",
      "\n",
      "Epoch 3/20 | Avg Loss: 0.1264\n",
      "Epoch 4, Loss: 0.0098\n",
      "\n",
      "Epoch 4/20 | Avg Loss: 0.0837\n",
      "Epoch 5, Loss: 0.0108\n",
      "\n",
      "Epoch 5/20 | Avg Loss: 0.0592\n",
      "Epoch 6, Loss: 0.2980\n",
      "\n",
      "Epoch 6/20 | Avg Loss: 0.0489\n",
      "Epoch 7, Loss: 0.0016\n",
      "\n",
      "Epoch 7/20 | Avg Loss: 0.0374\n",
      "Epoch 8, Loss: 0.1246\n",
      "\n",
      "Epoch 8/20 | Avg Loss: 0.0301\n",
      "Epoch 9, Loss: 0.0647\n",
      "\n",
      "Epoch 9/20 | Avg Loss: 0.0258\n",
      "Epoch 10, Loss: 0.0059\n",
      "\n",
      "Epoch 10/20 | Avg Loss: 0.0226\n",
      "Epoch 11, Loss: 0.0017\n",
      "\n",
      "Epoch 11/20 | Avg Loss: 0.0197\n",
      "Epoch 12, Loss: 0.0502\n",
      "\n",
      "Epoch 12/20 | Avg Loss: 0.0168\n",
      "Epoch 13, Loss: 0.0014\n",
      "\n",
      "Epoch 13/20 | Avg Loss: 0.0147\n",
      "Epoch 14, Loss: 0.0440\n",
      "\n",
      "Epoch 14/20 | Avg Loss: 0.0134\n",
      "Epoch 15, Loss: 0.0011\n",
      "\n",
      "Epoch 15/20 | Avg Loss: 0.0130\n",
      "Epoch 16, Loss: 0.0087\n",
      "\n",
      "Epoch 16/20 | Avg Loss: 0.0125\n",
      "Epoch 17, Loss: 0.0130\n",
      "\n",
      "Epoch 17/20 | Avg Loss: 0.0122\n",
      "Epoch 18, Loss: 0.0010\n",
      "\n",
      "Epoch 18/20 | Avg Loss: 0.0104\n",
      "Epoch 19, Loss: 0.0923\n",
      "\n",
      "Epoch 19/20 | Avg Loss: 0.0086\n",
      "Epoch 20, Loss: 0.0095\n",
      "\n",
      "Epoch 20/20 | Avg Loss: 0.0090\n",
      "Time train:  186.90603375434875 c\n",
      "\n",
      "=== Entity-level Metrics ===\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           coating       0.99      0.89      0.94       203\n",
      "             color       0.97      0.93      0.95       107\n",
      "           country       1.00      0.80      0.89        25\n",
      "              form       0.99      0.96      0.97       231\n",
      "            height       0.97      0.95      0.96       581\n",
      "        height_big       0.99      0.97      0.98       198\n",
      "      height_small       0.89      0.73      0.80        11\n",
      "    inner_diameter       0.99      0.97      0.98      1616\n",
      "            length       0.96      0.94      0.95      1714\n",
      "      manufacturer       0.99      0.85      0.92       153\n",
      "              mark       0.98      0.96      0.97      1043\n",
      "        mark_steal       0.99      0.99      0.99     10763\n",
      "   mark_steel_aisi       1.00      0.99      0.99      1333\n",
      "          material       0.99      0.99      0.99      2073\n",
      "    outer_diameter       0.99      0.96      0.97       604\n",
      "           package       0.93      0.90      0.92        30\n",
      "         precision       1.00      1.00      1.00        89\n",
      "           product       1.00      0.99      0.99      4783\n",
      "           purpose       0.97      0.64      0.77        50\n",
      "       standart_en       0.99      1.00      1.00       915\n",
      "     standart_gost       1.00      1.00      1.00      5271\n",
      "       standart_tu       0.98      0.95      0.96       364\n",
      "    strength_class       0.99      0.99      0.99       305\n",
      "strength_class_old       0.98      1.00      0.99       190\n",
      "         tehnology       0.98      0.99      0.99      1789\n",
      "         thickness       0.99      0.99      0.99      4632\n",
      "              type       0.99      0.98      0.99      1932\n",
      "             width       0.96      0.97      0.97      2020\n",
      "\n",
      "         micro avg       0.99      0.98      0.99     43025\n",
      "         macro avg       0.98      0.94      0.96     43025\n",
      "      weighted avg       0.99      0.98      0.99     43025\n",
      "\n",
      "\n",
      "=== Per-entity Metrics ===\n",
      "product:\n",
      "  Precision: 0.9966\n",
      "  Recall:    0.9902\n",
      "  F1-score:  0.9934\n",
      "  Support:   4783\n",
      "precision:\n",
      "  Precision: 1.0000\n",
      "  Recall:    1.0000\n",
      "  F1-score:  1.0000\n",
      "  Support:   89\n",
      "coating:\n",
      "  Precision: 0.9945\n",
      "  Recall:    0.8916\n",
      "  F1-score:  0.9403\n",
      "  Support:   203\n",
      "tehnology:\n",
      "  Precision: 0.9844\n",
      "  Recall:    0.9883\n",
      "  F1-score:  0.9863\n",
      "  Support:   1789\n",
      "strength_class:\n",
      "  Precision: 0.9901\n",
      "  Recall:    0.9869\n",
      "  F1-score:  0.9885\n",
      "  Support:   305\n",
      "package:\n",
      "  Precision: 0.9310\n",
      "  Recall:    0.9000\n",
      "  F1-score:  0.9153\n",
      "  Support:   30\n",
      "width:\n",
      "  Precision: 0.9627\n",
      "  Recall:    0.9703\n",
      "  F1-score:  0.9665\n",
      "  Support:   2020\n",
      "height_big:\n",
      "  Precision: 0.9948\n",
      "  Recall:    0.9747\n",
      "  F1-score:  0.9847\n",
      "  Support:   198\n",
      "color:\n",
      "  Precision: 0.9709\n",
      "  Recall:    0.9346\n",
      "  F1-score:  0.9524\n",
      "  Support:   107\n",
      "standart_en:\n",
      "  Precision: 0.9945\n",
      "  Recall:    0.9956\n",
      "  F1-score:  0.9951\n",
      "  Support:   915\n",
      "country:\n",
      "  Precision: 1.0000\n",
      "  Recall:    0.8000\n",
      "  F1-score:  0.8889\n",
      "  Support:   25\n",
      "inner_diameter:\n",
      "  Precision: 0.9862\n",
      "  Recall:    0.9715\n",
      "  F1-score:  0.9788\n",
      "  Support:   1616\n",
      "mark_steal:\n",
      "  Precision: 0.9918\n",
      "  Recall:    0.9939\n",
      "  F1-score:  0.9929\n",
      "  Support:   10763\n",
      "form:\n",
      "  Precision: 0.9867\n",
      "  Recall:    0.9610\n",
      "  F1-score:  0.9737\n",
      "  Support:   231\n",
      "length:\n",
      "  Precision: 0.9636\n",
      "  Recall:    0.9417\n",
      "  F1-score:  0.9525\n",
      "  Support:   1714\n",
      "purpose:\n",
      "  Precision: 0.9697\n",
      "  Recall:    0.6400\n",
      "  F1-score:  0.7711\n",
      "  Support:   50\n",
      "outer_diameter:\n",
      "  Precision: 0.9863\n",
      "  Recall:    0.9570\n",
      "  F1-score:  0.9714\n",
      "  Support:   604\n",
      "manufacturer:\n",
      "  Precision: 0.9924\n",
      "  Recall:    0.8497\n",
      "  F1-score:  0.9155\n",
      "  Support:   153\n",
      "mark:\n",
      "  Precision: 0.9823\n",
      "  Recall:    0.9597\n",
      "  F1-score:  0.9709\n",
      "  Support:   1043\n",
      "mark_steel_aisi:\n",
      "  Precision: 0.9977\n",
      "  Recall:    0.9887\n",
      "  F1-score:  0.9932\n",
      "  Support:   1333\n",
      "height_small:\n",
      "  Precision: 0.8889\n",
      "  Recall:    0.7273\n",
      "  F1-score:  0.8000\n",
      "  Support:   11\n",
      "strength_class_old:\n",
      "  Precision: 0.9845\n",
      "  Recall:    1.0000\n",
      "  F1-score:  0.9922\n",
      "  Support:   190\n",
      "standart_gost:\n",
      "  Precision: 0.9956\n",
      "  Recall:    0.9962\n",
      "  F1-score:  0.9959\n",
      "  Support:   5271\n",
      "material:\n",
      "  Precision: 0.9884\n",
      "  Recall:    0.9894\n",
      "  F1-score:  0.9889\n",
      "  Support:   2073\n",
      "standart_tu:\n",
      "  Precision: 0.9773\n",
      "  Recall:    0.9478\n",
      "  F1-score:  0.9623\n",
      "  Support:   364\n",
      "height:\n",
      "  Precision: 0.9685\n",
      "  Recall:    0.9518\n",
      "  F1-score:  0.9601\n",
      "  Support:   581\n",
      "type:\n",
      "  Precision: 0.9922\n",
      "  Recall:    0.9850\n",
      "  F1-score:  0.9886\n",
      "  Support:   1932\n",
      "thickness:\n",
      "  Precision: 0.9862\n",
      "  Recall:    0.9905\n",
      "  F1-score:  0.9884\n",
      "  Support:   4632\n",
      "Time inference:  2.4927046298980713  c\n"
     ]
    }
   ],
   "source": [
    "# Train simple CNN (1 layer) + LSTM\n",
    "time_start = time.time()\n",
    "model = UniversalCNN_NER(\n",
    "    vocab_size=10000,\n",
    "    embedding_dim=50,\n",
    "    num_tags=len(tag_encoder.classes_),\n",
    "    filter_sizes=[3],\n",
    "    num_filters=256,\n",
    "    use_lstm=True,\n",
    "    bidirectional=False\n",
    ")\n",
    "\n",
    "trained_model = train_model(\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    num_tags=len(tag_encoder.classes_),\n",
    "    epochs=20,\n",
    "    lr=1e-3\n",
    ")\n",
    "\n",
    "print('Time train: ', time.time() - time_start, 'c')\n",
    "\n",
    "time_start = time.time()\n",
    "metrics = evaluate_model(model, sample_data_test, vocab, tag_encoder)\n",
    "\n",
    "print(\"\\n=== Entity-level Metrics ===\")\n",
    "print(metrics['entity_level'])\n",
    "\n",
    "print(\"\\n=== Per-entity Metrics ===\")\n",
    "for entity, scores in metrics['entity_metrics'].items():\n",
    "    print(f\"{entity}:\")\n",
    "    print(f\"  Precision: {scores['precision']:.4f}\")\n",
    "    print(f\"  Recall:    {scores['recall']:.4f}\")\n",
    "    print(f\"  F1-score:  {scores['f1']:.4f}\")\n",
    "    print(f\"  Support:   {scores['support']}\")\n",
    "print(\"Time inference: \", time.time() - time_start, ' c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5562cbb9-a83b-405a-96bb-dcd6034a381d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.3573\n",
      "\n",
      "Epoch 1/20 | Avg Loss: 0.6224\n",
      "Epoch 2, Loss: 0.2820\n",
      "\n",
      "Epoch 2/20 | Avg Loss: 0.1732\n",
      "Epoch 3, Loss: 0.0279\n",
      "\n",
      "Epoch 3/20 | Avg Loss: 0.0939\n",
      "Epoch 4, Loss: 0.0797\n",
      "\n",
      "Epoch 4/20 | Avg Loss: 0.0611\n",
      "Epoch 5, Loss: 0.0320\n",
      "\n",
      "Epoch 5/20 | Avg Loss: 0.0424\n",
      "Epoch 6, Loss: 0.1321\n",
      "\n",
      "Epoch 6/20 | Avg Loss: 0.0317\n",
      "Epoch 7, Loss: 0.0876\n",
      "\n",
      "Epoch 7/20 | Avg Loss: 0.0234\n",
      "Epoch 8, Loss: 0.0232\n",
      "\n",
      "Epoch 8/20 | Avg Loss: 0.0182\n",
      "Epoch 9, Loss: 0.0015\n",
      "\n",
      "Epoch 9/20 | Avg Loss: 0.0160\n",
      "Epoch 10, Loss: 0.0299\n",
      "\n",
      "Epoch 10/20 | Avg Loss: 0.0128\n",
      "Epoch 11, Loss: 0.0078\n",
      "\n",
      "Epoch 11/20 | Avg Loss: 0.0120\n",
      "Epoch 12, Loss: 0.0345\n",
      "\n",
      "Epoch 12/20 | Avg Loss: 0.0105\n",
      "Epoch 13, Loss: 0.0117\n",
      "\n",
      "Epoch 13/20 | Avg Loss: 0.0095\n",
      "Epoch 14, Loss: 0.0034\n",
      "\n",
      "Epoch 14/20 | Avg Loss: 0.0114\n",
      "Epoch 15, Loss: 0.0037\n",
      "\n",
      "Epoch 15/20 | Avg Loss: 0.0083\n",
      "Epoch 16, Loss: 0.0108\n",
      "\n",
      "Epoch 16/20 | Avg Loss: 0.0058\n",
      "Epoch 17, Loss: 0.0003\n",
      "\n",
      "Epoch 17/20 | Avg Loss: 0.0068\n",
      "Epoch 18, Loss: 0.0011\n",
      "\n",
      "Epoch 18/20 | Avg Loss: 0.0070\n",
      "Epoch 19, Loss: 0.0017\n",
      "\n",
      "Epoch 19/20 | Avg Loss: 0.0074\n",
      "Epoch 20, Loss: 0.0001\n",
      "\n",
      "Epoch 20/20 | Avg Loss: 0.0057\n",
      "Time train:  239.78723645210266 c\n",
      "\n",
      "=== Entity-level Metrics ===\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           coating       0.99      0.91      0.95       203\n",
      "             color       0.96      0.94      0.95       107\n",
      "           country       0.95      0.80      0.87        25\n",
      "              form       0.97      0.96      0.97       231\n",
      "            height       0.98      0.98      0.98       581\n",
      "        height_big       1.00      0.97      0.98       198\n",
      "      height_small       1.00      0.73      0.84        11\n",
      "    inner_diameter       0.99      0.98      0.99      1616\n",
      "            length       0.96      0.95      0.96      1714\n",
      "      manufacturer       0.90      0.87      0.88       153\n",
      "              mark       0.98      0.97      0.97      1043\n",
      "        mark_steal       0.99      0.99      0.99     10763\n",
      "   mark_steel_aisi       0.99      1.00      0.99      1333\n",
      "          material       0.98      0.99      0.99      2073\n",
      "    outer_diameter       0.99      0.98      0.98       604\n",
      "           package       0.90      0.90      0.90        30\n",
      "         precision       1.00      1.00      1.00        89\n",
      "           product       1.00      0.99      0.99      4783\n",
      "           purpose       0.95      0.76      0.84        50\n",
      "       standart_en       0.88      1.00      0.93       915\n",
      "     standart_gost       1.00      1.00      1.00      5271\n",
      "       standart_tu       0.98      0.93      0.95       364\n",
      "    strength_class       0.99      1.00      1.00       305\n",
      "strength_class_old       0.98      0.99      0.99       190\n",
      "         tehnology       0.98      0.98      0.98      1789\n",
      "         thickness       0.99      0.99      0.99      4632\n",
      "              type       0.99      0.99      0.99      1932\n",
      "             width       0.98      0.98      0.98      2020\n",
      "\n",
      "         micro avg       0.99      0.99      0.99     43025\n",
      "         macro avg       0.97      0.95      0.96     43025\n",
      "      weighted avg       0.99      0.99      0.99     43025\n",
      "\n",
      "\n",
      "=== Per-entity Metrics ===\n",
      "product:\n",
      "  Precision: 0.9952\n",
      "  Recall:    0.9904\n",
      "  F1-score:  0.9928\n",
      "  Support:   4783\n",
      "precision:\n",
      "  Precision: 1.0000\n",
      "  Recall:    1.0000\n",
      "  F1-score:  1.0000\n",
      "  Support:   89\n",
      "coating:\n",
      "  Precision: 0.9946\n",
      "  Recall:    0.9113\n",
      "  F1-score:  0.9512\n",
      "  Support:   203\n",
      "tehnology:\n",
      "  Precision: 0.9831\n",
      "  Recall:    0.9782\n",
      "  F1-score:  0.9807\n",
      "  Support:   1789\n",
      "strength_class:\n",
      "  Precision: 0.9935\n",
      "  Recall:    0.9967\n",
      "  F1-score:  0.9951\n",
      "  Support:   305\n",
      "package:\n",
      "  Precision: 0.9000\n",
      "  Recall:    0.9000\n",
      "  F1-score:  0.9000\n",
      "  Support:   30\n",
      "width:\n",
      "  Precision: 0.9816\n",
      "  Recall:    0.9767\n",
      "  F1-score:  0.9792\n",
      "  Support:   2020\n",
      "height_big:\n",
      "  Precision: 1.0000\n",
      "  Recall:    0.9697\n",
      "  F1-score:  0.9846\n",
      "  Support:   198\n",
      "color:\n",
      "  Precision: 0.9619\n",
      "  Recall:    0.9439\n",
      "  F1-score:  0.9528\n",
      "  Support:   107\n",
      "standart_en:\n",
      "  Precision: 0.8796\n",
      "  Recall:    0.9978\n",
      "  F1-score:  0.9350\n",
      "  Support:   915\n",
      "country:\n",
      "  Precision: 0.9524\n",
      "  Recall:    0.8000\n",
      "  F1-score:  0.8696\n",
      "  Support:   25\n",
      "inner_diameter:\n",
      "  Precision: 0.9912\n",
      "  Recall:    0.9814\n",
      "  F1-score:  0.9863\n",
      "  Support:   1616\n",
      "mark_steal:\n",
      "  Precision: 0.9927\n",
      "  Recall:    0.9918\n",
      "  F1-score:  0.9922\n",
      "  Support:   10763\n",
      "form:\n",
      "  Precision: 0.9737\n",
      "  Recall:    0.9610\n",
      "  F1-score:  0.9673\n",
      "  Support:   231\n",
      "length:\n",
      "  Precision: 0.9612\n",
      "  Recall:    0.9545\n",
      "  F1-score:  0.9578\n",
      "  Support:   1714\n",
      "purpose:\n",
      "  Precision: 0.9500\n",
      "  Recall:    0.7600\n",
      "  F1-score:  0.8444\n",
      "  Support:   50\n",
      "outer_diameter:\n",
      "  Precision: 0.9883\n",
      "  Recall:    0.9801\n",
      "  F1-score:  0.9842\n",
      "  Support:   604\n",
      "manufacturer:\n",
      "  Precision: 0.8986\n",
      "  Recall:    0.8693\n",
      "  F1-score:  0.8837\n",
      "  Support:   153\n",
      "mark:\n",
      "  Precision: 0.9769\n",
      "  Recall:    0.9712\n",
      "  F1-score:  0.9740\n",
      "  Support:   1043\n",
      "mark_steel_aisi:\n",
      "  Precision: 0.9910\n",
      "  Recall:    0.9962\n",
      "  F1-score:  0.9936\n",
      "  Support:   1333\n",
      "height_small:\n",
      "  Precision: 1.0000\n",
      "  Recall:    0.7273\n",
      "  F1-score:  0.8421\n",
      "  Support:   11\n",
      "strength_class_old:\n",
      "  Precision: 0.9793\n",
      "  Recall:    0.9947\n",
      "  F1-score:  0.9869\n",
      "  Support:   190\n",
      "standart_gost:\n",
      "  Precision: 0.9968\n",
      "  Recall:    0.9956\n",
      "  F1-score:  0.9962\n",
      "  Support:   5271\n",
      "material:\n",
      "  Precision: 0.9818\n",
      "  Recall:    0.9894\n",
      "  F1-score:  0.9856\n",
      "  Support:   2073\n",
      "standart_tu:\n",
      "  Precision: 0.9826\n",
      "  Recall:    0.9286\n",
      "  F1-score:  0.9548\n",
      "  Support:   364\n",
      "height:\n",
      "  Precision: 0.9760\n",
      "  Recall:    0.9793\n",
      "  F1-score:  0.9777\n",
      "  Support:   581\n",
      "type:\n",
      "  Precision: 0.9891\n",
      "  Recall:    0.9881\n",
      "  F1-score:  0.9886\n",
      "  Support:   1932\n",
      "thickness:\n",
      "  Precision: 0.9905\n",
      "  Recall:    0.9916\n",
      "  F1-score:  0.9910\n",
      "  Support:   4632\n",
      "Time inference:  3.1822290420532227  c\n"
     ]
    }
   ],
   "source": [
    "# Train simple CNN (1 layer) + BiLSTM\n",
    "time_start = time.time()\n",
    "model = UniversalCNN_NER(\n",
    "    vocab_size=10000,\n",
    "    embedding_dim=50,\n",
    "    num_tags=len(tag_encoder.classes_),\n",
    "    filter_sizes=[3],\n",
    "    num_filters=256,\n",
    "    use_lstm=True\n",
    ")\n",
    "\n",
    "trained_model = train_model(\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    num_tags=len(tag_encoder.classes_),\n",
    "    epochs=20,\n",
    "    lr=1e-3\n",
    ")\n",
    "\n",
    "print('Time train: ', time.time() - time_start, 'c')\n",
    "\n",
    "time_start = time.time()\n",
    "metrics = evaluate_model(model, sample_data_test, vocab, tag_encoder)\n",
    "\n",
    "print(\"\\n=== Entity-level Metrics ===\")\n",
    "print(metrics['entity_level'])\n",
    "\n",
    "print(\"\\n=== Per-entity Metrics ===\")\n",
    "for entity, scores in metrics['entity_metrics'].items():\n",
    "    print(f\"{entity}:\")\n",
    "    print(f\"  Precision: {scores['precision']:.4f}\")\n",
    "    print(f\"  Recall:    {scores['recall']:.4f}\")\n",
    "    print(f\"  F1-score:  {scores['f1']:.4f}\")\n",
    "    print(f\"  Support:   {scores['support']}\")\n",
    "print(\"Time inference: \", time.time() - time_start, ' c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6d272aa8-1145-4635-8285-f89f4236f6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.4488\n",
      "\n",
      "Epoch 1/20 | Avg Loss: 0.6167\n",
      "Epoch 2, Loss: 0.0782\n",
      "\n",
      "Epoch 2/20 | Avg Loss: 0.1700\n",
      "Epoch 3, Loss: 0.0127\n",
      "\n",
      "Epoch 3/20 | Avg Loss: 0.0939\n",
      "Epoch 4, Loss: 0.0311\n",
      "\n",
      "Epoch 4/20 | Avg Loss: 0.0650\n",
      "Epoch 5, Loss: 0.0129\n",
      "\n",
      "Epoch 5/20 | Avg Loss: 0.0502\n",
      "Epoch 6, Loss: 0.0024\n",
      "\n",
      "Epoch 6/20 | Avg Loss: 0.0378\n",
      "Epoch 7, Loss: 0.0400\n",
      "\n",
      "Epoch 7/20 | Avg Loss: 0.0288\n",
      "Epoch 8, Loss: 0.0006\n",
      "\n",
      "Epoch 8/20 | Avg Loss: 0.0246\n",
      "Epoch 9, Loss: 0.0236\n",
      "\n",
      "Epoch 9/20 | Avg Loss: 0.0211\n",
      "Epoch 10, Loss: 0.0147\n",
      "\n",
      "Epoch 10/20 | Avg Loss: 0.0210\n",
      "Epoch 11, Loss: 0.0003\n",
      "\n",
      "Epoch 11/20 | Avg Loss: 0.0218\n",
      "Epoch 12, Loss: 0.0095\n",
      "\n",
      "Epoch 12/20 | Avg Loss: 0.0186\n",
      "Epoch 13, Loss: 0.0119\n",
      "\n",
      "Epoch 13/20 | Avg Loss: 0.0166\n",
      "Epoch 14, Loss: 0.0088\n",
      "\n",
      "Epoch 14/20 | Avg Loss: 0.0163\n",
      "Epoch 15, Loss: 0.0897\n",
      "\n",
      "Epoch 15/20 | Avg Loss: 0.0161\n",
      "Epoch 16, Loss: 0.0007\n",
      "\n",
      "Epoch 16/20 | Avg Loss: 0.0145\n",
      "Epoch 17, Loss: 0.0050\n",
      "\n",
      "Epoch 17/20 | Avg Loss: 0.0137\n",
      "Epoch 18, Loss: 0.0095\n",
      "\n",
      "Epoch 18/20 | Avg Loss: 0.0118\n",
      "Epoch 19, Loss: 0.0008\n",
      "\n",
      "Epoch 19/20 | Avg Loss: 0.0148\n",
      "Epoch 20, Loss: 0.0002\n",
      "\n",
      "Epoch 20/20 | Avg Loss: 0.0124\n",
      "Time train:  475.7570381164551 c\n",
      "\n",
      "=== Entity-level Metrics ===\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           coating       0.98      0.89      0.93       203\n",
      "             color       0.84      0.93      0.88       107\n",
      "           country       0.91      0.80      0.85        25\n",
      "              form       0.96      0.93      0.95       231\n",
      "            height       0.97      0.96      0.97       581\n",
      "        height_big       0.99      0.97      0.98       198\n",
      "      height_small       0.89      0.73      0.80        11\n",
      "    inner_diameter       0.97      0.98      0.98      1616\n",
      "            length       0.96      0.96      0.96      1714\n",
      "      manufacturer       0.96      0.87      0.91       153\n",
      "              mark       0.98      0.96      0.97      1043\n",
      "        mark_steal       0.99      0.99      0.99     10763\n",
      "   mark_steel_aisi       0.99      0.99      0.99      1333\n",
      "          material       0.99      0.99      0.99      2073\n",
      "    outer_diameter       0.99      0.95      0.97       604\n",
      "           package       0.87      0.90      0.89        30\n",
      "         precision       1.00      1.00      1.00        89\n",
      "           product       1.00      0.99      0.99      4783\n",
      "           purpose       0.97      0.64      0.77        50\n",
      "       standart_en       0.99      1.00      1.00       915\n",
      "     standart_gost       1.00      1.00      1.00      5271\n",
      "       standart_tu       0.95      0.99      0.97       364\n",
      "    strength_class       1.00      0.97      0.99       305\n",
      "strength_class_old       0.90      1.00      0.95       190\n",
      "         tehnology       0.98      0.99      0.98      1789\n",
      "         thickness       0.99      0.99      0.99      4632\n",
      "              type       0.99      0.99      0.99      1932\n",
      "             width       0.97      0.98      0.98      2020\n",
      "\n",
      "         micro avg       0.99      0.98      0.99     43025\n",
      "         macro avg       0.96      0.94      0.95     43025\n",
      "      weighted avg       0.99      0.98      0.99     43025\n",
      "\n",
      "\n",
      "=== Per-entity Metrics ===\n",
      "product:\n",
      "  Precision: 0.9960\n",
      "  Recall:    0.9902\n",
      "  F1-score:  0.9931\n",
      "  Support:   4783\n",
      "precision:\n",
      "  Precision: 1.0000\n",
      "  Recall:    1.0000\n",
      "  F1-score:  1.0000\n",
      "  Support:   89\n",
      "coating:\n",
      "  Precision: 0.9784\n",
      "  Recall:    0.8916\n",
      "  F1-score:  0.9330\n",
      "  Support:   203\n",
      "tehnology:\n",
      "  Precision: 0.9794\n",
      "  Recall:    0.9855\n",
      "  F1-score:  0.9824\n",
      "  Support:   1789\n",
      "strength_class:\n",
      "  Precision: 1.0000\n",
      "  Recall:    0.9705\n",
      "  F1-score:  0.9850\n",
      "  Support:   305\n",
      "package:\n",
      "  Precision: 0.8710\n",
      "  Recall:    0.9000\n",
      "  F1-score:  0.8852\n",
      "  Support:   30\n",
      "width:\n",
      "  Precision: 0.9725\n",
      "  Recall:    0.9807\n",
      "  F1-score:  0.9766\n",
      "  Support:   2020\n",
      "height_big:\n",
      "  Precision: 0.9948\n",
      "  Recall:    0.9747\n",
      "  F1-score:  0.9847\n",
      "  Support:   198\n",
      "color:\n",
      "  Precision: 0.8390\n",
      "  Recall:    0.9252\n",
      "  F1-score:  0.8800\n",
      "  Support:   107\n",
      "standart_en:\n",
      "  Precision: 0.9924\n",
      "  Recall:    0.9978\n",
      "  F1-score:  0.9951\n",
      "  Support:   915\n",
      "country:\n",
      "  Precision: 0.9091\n",
      "  Recall:    0.8000\n",
      "  F1-score:  0.8511\n",
      "  Support:   25\n",
      "inner_diameter:\n",
      "  Precision: 0.9723\n",
      "  Recall:    0.9790\n",
      "  F1-score:  0.9756\n",
      "  Support:   1616\n",
      "mark_steal:\n",
      "  Precision: 0.9888\n",
      "  Recall:    0.9921\n",
      "  F1-score:  0.9904\n",
      "  Support:   10763\n",
      "form:\n",
      "  Precision: 0.9641\n",
      "  Recall:    0.9307\n",
      "  F1-score:  0.9471\n",
      "  Support:   231\n",
      "length:\n",
      "  Precision: 0.9650\n",
      "  Recall:    0.9638\n",
      "  F1-score:  0.9644\n",
      "  Support:   1714\n",
      "purpose:\n",
      "  Precision: 0.9697\n",
      "  Recall:    0.6400\n",
      "  F1-score:  0.7711\n",
      "  Support:   50\n",
      "outer_diameter:\n",
      "  Precision: 0.9863\n",
      "  Recall:    0.9520\n",
      "  F1-score:  0.9688\n",
      "  Support:   604\n",
      "manufacturer:\n",
      "  Precision: 0.9568\n",
      "  Recall:    0.8693\n",
      "  F1-score:  0.9110\n",
      "  Support:   153\n",
      "mark:\n",
      "  Precision: 0.9766\n",
      "  Recall:    0.9616\n",
      "  F1-score:  0.9691\n",
      "  Support:   1043\n",
      "mark_steel_aisi:\n",
      "  Precision: 0.9910\n",
      "  Recall:    0.9917\n",
      "  F1-score:  0.9914\n",
      "  Support:   1333\n",
      "height_small:\n",
      "  Precision: 0.8889\n",
      "  Recall:    0.7273\n",
      "  F1-score:  0.8000\n",
      "  Support:   11\n",
      "strength_class_old:\n",
      "  Precision: 0.9048\n",
      "  Recall:    1.0000\n",
      "  F1-score:  0.9500\n",
      "  Support:   190\n",
      "standart_gost:\n",
      "  Precision: 0.9966\n",
      "  Recall:    0.9954\n",
      "  F1-score:  0.9960\n",
      "  Support:   5271\n",
      "material:\n",
      "  Precision: 0.9875\n",
      "  Recall:    0.9875\n",
      "  F1-score:  0.9875\n",
      "  Support:   2073\n",
      "standart_tu:\n",
      "  Precision: 0.9526\n",
      "  Recall:    0.9945\n",
      "  F1-score:  0.9731\n",
      "  Support:   364\n",
      "height:\n",
      "  Precision: 0.9688\n",
      "  Recall:    0.9621\n",
      "  F1-score:  0.9655\n",
      "  Support:   581\n",
      "type:\n",
      "  Precision: 0.9865\n",
      "  Recall:    0.9855\n",
      "  F1-score:  0.9860\n",
      "  Support:   1932\n",
      "thickness:\n",
      "  Precision: 0.9928\n",
      "  Recall:    0.9864\n",
      "  F1-score:  0.9896\n",
      "  Support:   4632\n",
      "Time inference:  3.8273446559906006  c\n"
     ]
    }
   ],
   "source": [
    "# Train simple CNN (2 layer) + BiLSTM\n",
    "time_start = time.time()\n",
    "model = UniversalCNN_NER(\n",
    "    vocab_size=10000,\n",
    "    embedding_dim=50,\n",
    "    num_tags=len(tag_encoder.classes_),\n",
    "    filter_sizes=[3, 5],\n",
    "    num_filters=256,\n",
    "    use_lstm=True\n",
    ")\n",
    "\n",
    "trained_model = train_model(\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    num_tags=len(tag_encoder.classes_),\n",
    "    epochs=20,\n",
    "    lr=1e-3\n",
    ")\n",
    "\n",
    "print('Time train: ', time.time() - time_start, 'c')\n",
    "\n",
    "time_start = time.time()\n",
    "metrics = evaluate_model(model, sample_data_test, vocab, tag_encoder)\n",
    "\n",
    "print(\"\\n=== Entity-level Metrics ===\")\n",
    "print(metrics['entity_level'])\n",
    "\n",
    "print(\"\\n=== Per-entity Metrics ===\")\n",
    "for entity, scores in metrics['entity_metrics'].items():\n",
    "    print(f\"{entity}:\")\n",
    "    print(f\"  Precision: {scores['precision']:.4f}\")\n",
    "    print(f\"  Recall:    {scores['recall']:.4f}\")\n",
    "    print(f\"  F1-score:  {scores['f1']:.4f}\")\n",
    "    print(f\"  Support:   {scores['support']}\")\n",
    "print(\"Time inference: \", time.time() - time_start, ' c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fedf02a5-8bc3-4e2f-9fe4-5a65706872e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0735\n",
      "\n",
      "Epoch 1/20 | Avg Loss: 0.6616\n",
      "Epoch 2, Loss: 0.2923\n",
      "\n",
      "Epoch 2/20 | Avg Loss: 0.1981\n",
      "Epoch 3, Loss: 0.0450\n",
      "\n",
      "Epoch 3/20 | Avg Loss: 0.1191\n",
      "Epoch 4, Loss: 0.0035\n",
      "\n",
      "Epoch 4/20 | Avg Loss: 0.0823\n",
      "Epoch 5, Loss: 0.1976\n",
      "\n",
      "Epoch 5/20 | Avg Loss: 0.0619\n",
      "Epoch 6, Loss: 0.0131\n",
      "\n",
      "Epoch 6/20 | Avg Loss: 0.0520\n",
      "Epoch 7, Loss: 0.0064\n",
      "\n",
      "Epoch 7/20 | Avg Loss: 0.0422\n",
      "Epoch 8, Loss: 0.0074\n",
      "\n",
      "Epoch 8/20 | Avg Loss: 0.0341\n",
      "Epoch 9, Loss: 0.0116\n",
      "\n",
      "Epoch 9/20 | Avg Loss: 0.0300\n",
      "Epoch 10, Loss: 0.0018\n",
      "\n",
      "Epoch 10/20 | Avg Loss: 0.0259\n",
      "Epoch 11, Loss: 0.2246\n",
      "\n",
      "Epoch 11/20 | Avg Loss: 0.0249\n",
      "Epoch 12, Loss: 0.0042\n",
      "\n",
      "Epoch 12/20 | Avg Loss: 0.0253\n",
      "Epoch 13, Loss: 0.0069\n",
      "\n",
      "Epoch 13/20 | Avg Loss: 0.0229\n",
      "Epoch 14, Loss: 0.0051\n",
      "\n",
      "Epoch 14/20 | Avg Loss: 0.0212\n",
      "Epoch 15, Loss: 0.0219\n",
      "\n",
      "Epoch 15/20 | Avg Loss: 0.0197\n",
      "Epoch 16, Loss: 0.1209\n",
      "\n",
      "Epoch 16/20 | Avg Loss: 0.0204\n",
      "Epoch 17, Loss: 0.0007\n",
      "\n",
      "Epoch 17/20 | Avg Loss: 0.0162\n",
      "Epoch 18, Loss: 0.0210\n",
      "\n",
      "Epoch 18/20 | Avg Loss: 0.0174\n",
      "Epoch 19, Loss: 0.0093\n",
      "\n",
      "Epoch 19/20 | Avg Loss: 0.0150\n",
      "Epoch 20, Loss: 0.0346\n",
      "\n",
      "Epoch 20/20 | Avg Loss: 0.0174\n",
      "Time train:  361.55380415916443 c\n",
      "\n",
      "=== Entity-level Metrics ===\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           coating       0.99      0.88      0.93       203\n",
      "             color       0.94      0.93      0.93       107\n",
      "           country       0.72      0.84      0.78        25\n",
      "              form       0.99      0.93      0.96       231\n",
      "            height       0.98      0.95      0.96       581\n",
      "        height_big       0.97      0.98      0.98       198\n",
      "      height_small       1.00      0.73      0.84        11\n",
      "    inner_diameter       0.99      0.97      0.98      1616\n",
      "            length       0.97      0.95      0.96      1714\n",
      "      manufacturer       0.98      0.84      0.91       153\n",
      "              mark       0.97      0.97      0.97      1043\n",
      "        mark_steal       0.99      0.99      0.99     10763\n",
      "   mark_steel_aisi       0.98      0.99      0.99      1333\n",
      "          material       0.99      0.99      0.99      2073\n",
      "    outer_diameter       0.96      0.97      0.97       604\n",
      "           package       0.97      0.97      0.97        30\n",
      "         precision       1.00      1.00      1.00        89\n",
      "           product       1.00      0.99      0.99      4783\n",
      "           purpose       1.00      0.60      0.75        50\n",
      "       standart_en       0.99      1.00      0.99       915\n",
      "     standart_gost       1.00      1.00      1.00      5271\n",
      "       standart_tu       0.96      0.98      0.97       364\n",
      "    strength_class       1.00      0.97      0.98       305\n",
      "strength_class_old       0.92      1.00      0.96       190\n",
      "         tehnology       0.98      0.99      0.99      1789\n",
      "         thickness       0.99      0.99      0.99      4632\n",
      "              type       0.99      0.98      0.99      1932\n",
      "             width       0.96      0.98      0.97      2020\n",
      "\n",
      "         micro avg       0.99      0.98      0.99     43025\n",
      "         macro avg       0.97      0.94      0.95     43025\n",
      "      weighted avg       0.99      0.98      0.98     43025\n",
      "\n",
      "\n",
      "=== Per-entity Metrics ===\n",
      "product:\n",
      "  Precision: 0.9952\n",
      "  Recall:    0.9904\n",
      "  F1-score:  0.9928\n",
      "  Support:   4783\n",
      "precision:\n",
      "  Precision: 1.0000\n",
      "  Recall:    1.0000\n",
      "  F1-score:  1.0000\n",
      "  Support:   89\n",
      "coating:\n",
      "  Precision: 0.9889\n",
      "  Recall:    0.8768\n",
      "  F1-score:  0.9295\n",
      "  Support:   203\n",
      "tehnology:\n",
      "  Precision: 0.9806\n",
      "  Recall:    0.9899\n",
      "  F1-score:  0.9853\n",
      "  Support:   1789\n",
      "strength_class:\n",
      "  Precision: 1.0000\n",
      "  Recall:    0.9672\n",
      "  F1-score:  0.9833\n",
      "  Support:   305\n",
      "package:\n",
      "  Precision: 0.9667\n",
      "  Recall:    0.9667\n",
      "  F1-score:  0.9667\n",
      "  Support:   30\n",
      "width:\n",
      "  Precision: 0.9622\n",
      "  Recall:    0.9822\n",
      "  F1-score:  0.9721\n",
      "  Support:   2020\n",
      "height_big:\n",
      "  Precision: 0.9749\n",
      "  Recall:    0.9798\n",
      "  F1-score:  0.9773\n",
      "  Support:   198\n",
      "color:\n",
      "  Precision: 0.9429\n",
      "  Recall:    0.9252\n",
      "  F1-score:  0.9340\n",
      "  Support:   107\n",
      "standart_en:\n",
      "  Precision: 0.9913\n",
      "  Recall:    0.9978\n",
      "  F1-score:  0.9946\n",
      "  Support:   915\n",
      "country:\n",
      "  Precision: 0.7241\n",
      "  Recall:    0.8400\n",
      "  F1-score:  0.7778\n",
      "  Support:   25\n",
      "inner_diameter:\n",
      "  Precision: 0.9893\n",
      "  Recall:    0.9684\n",
      "  F1-score:  0.9787\n",
      "  Support:   1616\n",
      "mark_steal:\n",
      "  Precision: 0.9858\n",
      "  Recall:    0.9934\n",
      "  F1-score:  0.9896\n",
      "  Support:   10763\n",
      "form:\n",
      "  Precision: 0.9862\n",
      "  Recall:    0.9307\n",
      "  F1-score:  0.9577\n",
      "  Support:   231\n",
      "length:\n",
      "  Precision: 0.9744\n",
      "  Recall:    0.9545\n",
      "  F1-score:  0.9643\n",
      "  Support:   1714\n",
      "purpose:\n",
      "  Precision: 1.0000\n",
      "  Recall:    0.6000\n",
      "  F1-score:  0.7500\n",
      "  Support:   50\n",
      "outer_diameter:\n",
      "  Precision: 0.9622\n",
      "  Recall:    0.9702\n",
      "  F1-score:  0.9662\n",
      "  Support:   604\n",
      "manufacturer:\n",
      "  Precision: 0.9773\n",
      "  Recall:    0.8431\n",
      "  F1-score:  0.9053\n",
      "  Support:   153\n",
      "mark:\n",
      "  Precision: 0.9693\n",
      "  Recall:    0.9703\n",
      "  F1-score:  0.9698\n",
      "  Support:   1043\n",
      "mark_steel_aisi:\n",
      "  Precision: 0.9800\n",
      "  Recall:    0.9940\n",
      "  F1-score:  0.9870\n",
      "  Support:   1333\n",
      "height_small:\n",
      "  Precision: 1.0000\n",
      "  Recall:    0.7273\n",
      "  F1-score:  0.8421\n",
      "  Support:   11\n",
      "strength_class_old:\n",
      "  Precision: 0.9223\n",
      "  Recall:    1.0000\n",
      "  F1-score:  0.9596\n",
      "  Support:   190\n",
      "standart_gost:\n",
      "  Precision: 0.9968\n",
      "  Recall:    0.9954\n",
      "  F1-score:  0.9961\n",
      "  Support:   5271\n",
      "material:\n",
      "  Precision: 0.9851\n",
      "  Recall:    0.9860\n",
      "  F1-score:  0.9855\n",
      "  Support:   2073\n",
      "standart_tu:\n",
      "  Precision: 0.9624\n",
      "  Recall:    0.9835\n",
      "  F1-score:  0.9728\n",
      "  Support:   364\n",
      "height:\n",
      "  Precision: 0.9786\n",
      "  Recall:    0.9466\n",
      "  F1-score:  0.9624\n",
      "  Support:   581\n",
      "type:\n",
      "  Precision: 0.9906\n",
      "  Recall:    0.9814\n",
      "  F1-score:  0.9860\n",
      "  Support:   1932\n",
      "thickness:\n",
      "  Precision: 0.9871\n",
      "  Recall:    0.9888\n",
      "  F1-score:  0.9879\n",
      "  Support:   4632\n",
      "Time inference:  3.1693482398986816  c\n"
     ]
    }
   ],
   "source": [
    "# Train simple CNN (2 layer) + LSTM\n",
    "time_start = time.time()\n",
    "model = UniversalCNN_NER(\n",
    "    vocab_size=10000,\n",
    "    embedding_dim=50,\n",
    "    num_tags=len(tag_encoder.classes_),\n",
    "    filter_sizes=[3, 5],\n",
    "    num_filters=256,\n",
    "    use_lstm=True,\n",
    "    bidirectional=False\n",
    ")\n",
    "\n",
    "trained_model = train_model(\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    num_tags=len(tag_encoder.classes_),\n",
    "    epochs=20,\n",
    "    lr=1e-3\n",
    ")\n",
    "\n",
    "print('Time train: ', time.time() - time_start, 'c')\n",
    "\n",
    "time_start = time.time()\n",
    "metrics = evaluate_model(model, sample_data_test, vocab, tag_encoder)\n",
    "\n",
    "print(\"\\n=== Entity-level Metrics ===\")\n",
    "print(metrics['entity_level'])\n",
    "\n",
    "print(\"\\n=== Per-entity Metrics ===\")\n",
    "for entity, scores in metrics['entity_metrics'].items():\n",
    "    print(f\"{entity}:\")\n",
    "    print(f\"  Precision: {scores['precision']:.4f}\")\n",
    "    print(f\"  Recall:    {scores['recall']:.4f}\")\n",
    "    print(f\"  F1-score:  {scores['f1']:.4f}\")\n",
    "    print(f\"  Support:   {scores['support']}\")\n",
    "print(\"Time inference: \", time.time() - time_start, ' c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ec8a4d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.3519\n",
      "\n",
      "Epoch 1/20 | Avg Loss: 0.6049\n",
      "Epoch 2, Loss: 0.0776\n",
      "\n",
      "Epoch 2/20 | Avg Loss: 0.1845\n",
      "Epoch 3, Loss: 0.0254\n",
      "\n",
      "Epoch 3/20 | Avg Loss: 0.1046\n",
      "Epoch 4, Loss: 0.1597\n",
      "\n",
      "Epoch 4/20 | Avg Loss: 0.0720\n",
      "Epoch 5, Loss: 0.2079\n",
      "\n",
      "Epoch 5/20 | Avg Loss: 0.0487\n",
      "Epoch 6, Loss: 0.0152\n",
      "\n",
      "Epoch 6/20 | Avg Loss: 0.0363\n",
      "Epoch 7, Loss: 0.0726\n",
      "\n",
      "Epoch 7/20 | Avg Loss: 0.0282\n",
      "Epoch 8, Loss: 0.0023\n",
      "\n",
      "Epoch 8/20 | Avg Loss: 0.0227\n",
      "Epoch 9, Loss: 0.0384\n",
      "\n",
      "Epoch 9/20 | Avg Loss: 0.0191\n",
      "Epoch 10, Loss: 0.0063\n",
      "\n",
      "Epoch 10/20 | Avg Loss: 0.0183\n",
      "Epoch 11, Loss: 0.1301\n",
      "\n",
      "Epoch 11/20 | Avg Loss: 0.0178\n",
      "Epoch 12, Loss: 0.0016\n",
      "\n",
      "Epoch 12/20 | Avg Loss: 0.0169\n",
      "Epoch 13, Loss: 0.0026\n",
      "\n",
      "Epoch 13/20 | Avg Loss: 0.0129\n",
      "Epoch 14, Loss: 0.0045\n",
      "\n",
      "Epoch 14/20 | Avg Loss: 0.0140\n",
      "Epoch 15, Loss: 0.0142\n",
      "\n",
      "Epoch 15/20 | Avg Loss: 0.0136\n",
      "Epoch 16, Loss: 0.0859\n",
      "\n",
      "Epoch 16/20 | Avg Loss: 0.0112\n",
      "Epoch 17, Loss: 0.0074\n",
      "\n",
      "Epoch 17/20 | Avg Loss: 0.0117\n",
      "Epoch 18, Loss: 0.0010\n",
      "\n",
      "Epoch 18/20 | Avg Loss: 0.0084\n",
      "Epoch 19, Loss: 0.0195\n",
      "\n",
      "Epoch 19/20 | Avg Loss: 0.0079\n",
      "Epoch 20, Loss: 0.0024\n",
      "\n",
      "Epoch 20/20 | Avg Loss: 0.0090\n",
      "Time train:  429.1884536743164 c\n",
      "\n",
      "=== Entity-level Metrics ===\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           coating       0.99      0.89      0.94       203\n",
      "             color       0.99      0.92      0.95       107\n",
      "           country       1.00      0.84      0.91        25\n",
      "              form       1.00      0.97      0.98       231\n",
      "            height       0.98      0.95      0.97       581\n",
      "        height_big       0.99      0.98      0.98       198\n",
      "      height_small       0.89      0.73      0.80        11\n",
      "    inner_diameter       0.98      0.98      0.98      1616\n",
      "            length       0.96      0.97      0.96      1714\n",
      "      manufacturer       0.98      0.86      0.91       153\n",
      "              mark       0.98      0.97      0.98      1043\n",
      "        mark_steal       0.99      0.99      0.99     10763\n",
      "   mark_steel_aisi       0.99      0.99      0.99      1333\n",
      "          material       0.99      0.99      0.99      2073\n",
      "    outer_diameter       1.00      0.96      0.98       604\n",
      "           package       1.00      0.97      0.98        30\n",
      "         precision       1.00      1.00      1.00        89\n",
      "           product       1.00      0.99      0.99      4783\n",
      "           purpose       0.97      0.76      0.85        50\n",
      "       standart_en       1.00      0.98      0.99       915\n",
      "     standart_gost       0.99      1.00      0.99      5271\n",
      "       standart_tu       0.99      0.96      0.97       364\n",
      "    strength_class       1.00      1.00      1.00       305\n",
      "strength_class_old       0.98      1.00      0.99       190\n",
      "         tehnology       0.99      0.99      0.99      1789\n",
      "         thickness       0.98      0.99      0.99      4632\n",
      "              type       0.99      0.98      0.99      1932\n",
      "             width       0.98      0.96      0.97      2020\n",
      "\n",
      "         micro avg       0.99      0.99      0.99     43025\n",
      "         macro avg       0.98      0.95      0.97     43025\n",
      "      weighted avg       0.99      0.99      0.99     43025\n",
      "\n",
      "\n",
      "=== Per-entity Metrics ===\n",
      "product:\n",
      "  Precision: 0.9958\n",
      "  Recall:    0.9908\n",
      "  F1-score:  0.9933\n",
      "  Support:   4783\n",
      "precision:\n",
      "  Precision: 1.0000\n",
      "  Recall:    1.0000\n",
      "  F1-score:  1.0000\n",
      "  Support:   89\n",
      "coating:\n",
      "  Precision: 0.9945\n",
      "  Recall:    0.8867\n",
      "  F1-score:  0.9375\n",
      "  Support:   203\n",
      "tehnology:\n",
      "  Precision: 0.9877\n",
      "  Recall:    0.9883\n",
      "  F1-score:  0.9880\n",
      "  Support:   1789\n",
      "strength_class:\n",
      "  Precision: 0.9967\n",
      "  Recall:    0.9967\n",
      "  F1-score:  0.9967\n",
      "  Support:   305\n",
      "package:\n",
      "  Precision: 1.0000\n",
      "  Recall:    0.9667\n",
      "  F1-score:  0.9831\n",
      "  Support:   30\n",
      "width:\n",
      "  Precision: 0.9833\n",
      "  Recall:    0.9639\n",
      "  F1-score:  0.9735\n",
      "  Support:   2020\n",
      "height_big:\n",
      "  Precision: 0.9898\n",
      "  Recall:    0.9798\n",
      "  F1-score:  0.9848\n",
      "  Support:   198\n",
      "color:\n",
      "  Precision: 0.9899\n",
      "  Recall:    0.9159\n",
      "  F1-score:  0.9515\n",
      "  Support:   107\n",
      "standart_en:\n",
      "  Precision: 0.9956\n",
      "  Recall:    0.9825\n",
      "  F1-score:  0.9890\n",
      "  Support:   915\n",
      "country:\n",
      "  Precision: 1.0000\n",
      "  Recall:    0.8400\n",
      "  F1-score:  0.9130\n",
      "  Support:   25\n",
      "inner_diameter:\n",
      "  Precision: 0.9808\n",
      "  Recall:    0.9814\n",
      "  F1-score:  0.9811\n",
      "  Support:   1616\n",
      "mark_steal:\n",
      "  Precision: 0.9945\n",
      "  Recall:    0.9916\n",
      "  F1-score:  0.9931\n",
      "  Support:   10763\n",
      "form:\n",
      "  Precision: 0.9955\n",
      "  Recall:    0.9654\n",
      "  F1-score:  0.9802\n",
      "  Support:   231\n",
      "length:\n",
      "  Precision: 0.9584\n",
      "  Recall:    0.9679\n",
      "  F1-score:  0.9631\n",
      "  Support:   1714\n",
      "purpose:\n",
      "  Precision: 0.9744\n",
      "  Recall:    0.7600\n",
      "  F1-score:  0.8539\n",
      "  Support:   50\n",
      "outer_diameter:\n",
      "  Precision: 0.9983\n",
      "  Recall:    0.9619\n",
      "  F1-score:  0.9798\n",
      "  Support:   604\n",
      "manufacturer:\n",
      "  Precision: 0.9776\n",
      "  Recall:    0.8562\n",
      "  F1-score:  0.9129\n",
      "  Support:   153\n",
      "mark:\n",
      "  Precision: 0.9816\n",
      "  Recall:    0.9712\n",
      "  F1-score:  0.9764\n",
      "  Support:   1043\n",
      "mark_steel_aisi:\n",
      "  Precision: 0.9903\n",
      "  Recall:    0.9925\n",
      "  F1-score:  0.9914\n",
      "  Support:   1333\n",
      "height_small:\n",
      "  Precision: 0.8889\n",
      "  Recall:    0.7273\n",
      "  F1-score:  0.8000\n",
      "  Support:   11\n",
      "strength_class_old:\n",
      "  Precision: 0.9794\n",
      "  Recall:    1.0000\n",
      "  F1-score:  0.9896\n",
      "  Support:   190\n",
      "standart_gost:\n",
      "  Precision: 0.9928\n",
      "  Recall:    0.9966\n",
      "  F1-score:  0.9947\n",
      "  Support:   5271\n",
      "material:\n",
      "  Precision: 0.9851\n",
      "  Recall:    0.9860\n",
      "  F1-score:  0.9855\n",
      "  Support:   2073\n",
      "standart_tu:\n",
      "  Precision: 0.9915\n",
      "  Recall:    0.9560\n",
      "  F1-score:  0.9734\n",
      "  Support:   364\n",
      "height:\n",
      "  Precision: 0.9840\n",
      "  Recall:    0.9501\n",
      "  F1-score:  0.9667\n",
      "  Support:   581\n",
      "type:\n",
      "  Precision: 0.9927\n",
      "  Recall:    0.9845\n",
      "  F1-score:  0.9886\n",
      "  Support:   1932\n",
      "thickness:\n",
      "  Precision: 0.9785\n",
      "  Recall:    0.9942\n",
      "  F1-score:  0.9863\n",
      "  Support:   4632\n",
      "Time inference:  3.2261974811553955  c\n"
     ]
    }
   ],
   "source": [
    "# Train simple CNN (1 layer) + BiLSTM + Layernorm\n",
    "time_start = time.time()\n",
    "model = UniversalCNN_NER(\n",
    "    vocab_size=10000,\n",
    "    embedding_dim=50,\n",
    "    num_tags=len(tag_encoder.classes_),\n",
    "    filter_sizes=[3],\n",
    "    num_filters=256,\n",
    "    use_lstm=True,\n",
    "    use_layernorm=True\n",
    ")\n",
    "\n",
    "trained_model = train_model(\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    num_tags=len(tag_encoder.classes_),\n",
    "    epochs=20,\n",
    "    lr=1e-3\n",
    ")\n",
    "\n",
    "print('Time train: ', time.time() - time_start, 'c')\n",
    "\n",
    "time_start = time.time()\n",
    "metrics = evaluate_model(model, sample_data_test, vocab, tag_encoder)\n",
    "\n",
    "print(\"\\n=== Entity-level Metrics ===\")\n",
    "print(metrics['entity_level'])\n",
    "\n",
    "print(\"\\n=== Per-entity Metrics ===\")\n",
    "for entity, scores in metrics['entity_metrics'].items():\n",
    "    print(f\"{entity}:\")\n",
    "    print(f\"  Precision: {scores['precision']:.4f}\")\n",
    "    print(f\"  Recall:    {scores['recall']:.4f}\")\n",
    "    print(f\"  F1-score:  {scores['f1']:.4f}\")\n",
    "    print(f\"  Support:   {scores['support']}\")\n",
    "print(\"Time inference: \", time.time() - time_start, ' c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c501820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "квадрат -> product\n",
      "70 -> width\n",
      "100 -> height\n",
      "ст3 -> mark_steal\n",
      "сп -> mark_steal\n",
      "- -> mark_steal\n",
      "2 -> mark_steal\n",
      "6000 -> length\n",
      "гост -> standart_gost\n",
      "2591 -> standart_gost\n",
      "- -> standart_gost\n",
      "88 -> standart_gost\n"
     ]
    }
   ],
   "source": [
    "# Тестирование\n",
    "test = 'квадрат 70 x 100 ст3 сп - 2, 6000 гост 2591 - 88 vvf'\n",
    "test_sentence = tokenizer(test)\n",
    "predicted_tags = predict(model, test_sentence, vocab, tag_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d61262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
