{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03cf21d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "from spacy.training import Example\n",
    "from spacy.scorer import Scorer\n",
    "from spacy_transformers import TransformerModel\n",
    "from typing import List, Tuple, Dict, Any, Optional, Union\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a66e0975",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    def load_data(self, \n",
    "                file_path: str,\n",
    "                text_key: str = \"text\",\n",
    "                possible_entity_keys: List[str] = [\"label\", \"entities\", \"annotations\"],\n",
    "                comment_key: str = \"Comments\") -> List[Dict]:\n",
    "        data = []\n",
    "        line_num = 0\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                for line in tqdm(f, desc=\"Download data\"):\n",
    "                    line_num += 1\n",
    "                    line = line.strip()\n",
    "                    if not line:\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        item = json.loads(line)\n",
    "                        \n",
    "                        # Check field with text\n",
    "                        if text_key not in item:\n",
    "                            print(f\"⚠️ Lime {line_num}: not key '{text_key}'\")\n",
    "                            continue\n",
    "                        \n",
    "                        # Find key with annotation\n",
    "                        entities = []\n",
    "                        for key in possible_entity_keys:\n",
    "                            if key in item:\n",
    "                                entities = item[key]\n",
    "                                break\n",
    "                        \n",
    "                        # Convert format\n",
    "                        unified_entities = self._convert_entities(entities, item[text_key])\n",
    "                        \n",
    "                        data.append({\n",
    "                            \"text\": item[text_key],\n",
    "                            \"entities\": unified_entities,\n",
    "                            \"comments\": item.get(comment_key, [])\n",
    "                        })\n",
    "                        \n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"Line {line_num}: Error JSON (skipped)\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Line {line_num}: {str(e)}\")\n",
    "        \n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "        \n",
    "        print(f\"Succes download {len(data)} row\")\n",
    "        return data\n",
    "    \n",
    "    def _convert_entities(self, \n",
    "                        entities: Union[List, Dict], \n",
    "                        text: str) -> List[Dict]:\n",
    "        converted = []\n",
    "        \n",
    "        if not entities:\n",
    "            return converted\n",
    "        \n",
    "        first_item = entities[0]\n",
    "        \n",
    "        # Format Doccano v1: [start, end, label]\n",
    "        if isinstance(first_item, list) and len(first_item) == 3:\n",
    "            for start, end, label in entities:\n",
    "                converted.append({\n",
    "                    \"start\": int(start),\n",
    "                    \"end\": int(end),\n",
    "                    \"label\": str(label)\n",
    "                })\n",
    "        \n",
    "        # Format Doccano v2/standart: {\"start\": X, \"end\": Y, ...}\n",
    "        elif isinstance(first_item, dict):\n",
    "            for ent in entities:\n",
    "                # Extract key\n",
    "                start_key = \"start\" if \"start\" in ent else \"start_offset\"\n",
    "                end_key = \"end\" if \"end\" in ent else \"end_offset\"\n",
    "                label_key = \"label\" if \"label\" in ent else \"tag\"\n",
    "                \n",
    "                converted.append({\n",
    "                    \"start\": int(ent[start_key]),\n",
    "                    \"end\": int(ent[end_key]),\n",
    "                    \"label\": str(ent[label_key])\n",
    "                })\n",
    "        \n",
    "        return converted\n",
    "    \n",
    "    def prepare_data(self, \n",
    "                    data: List[Dict],\n",
    "                    validate: bool = True) -> List[Tuple[str, Dict]]:\n",
    "        formatted_data = []\n",
    "        error_count = 0\n",
    "        \n",
    "        for item in tqdm(data, desc=\"Prepare data\"):\n",
    "            try:\n",
    "                text = item[\"text\"]\n",
    "                entities = []\n",
    "                \n",
    "                for ent in item[\"entities\"]:\n",
    "                    start = ent[\"start\"]\n",
    "                    end = ent[\"end\"]\n",
    "                    label = ent[\"label\"]\n",
    "                    \n",
    "                    if validate:\n",
    "                        # Check correct annotation\n",
    "                        if not (0 <= start <= end <= len(text)):\n",
    "                            raise ValueError(\n",
    "                                f\"Incorrect position: {start}-{end} \"\n",
    "                                f\"for text line {len(text)}. Text: '{text[start:end]}'\"\n",
    "                            )\n",
    "                        \n",
    "                        # Check mark not empty\n",
    "                        if not label.strip():\n",
    "                            raise ValueError(f\"Empty mark for position {start}-{end}\")\n",
    "                    \n",
    "                    entities.append((start, end, label))\n",
    "                \n",
    "                formatted_data.append((text, {\"entities\": entities}))\n",
    "            except Exception as e:\n",
    "                error_count += 1\n",
    "                print(f\"Error in element: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        if error_count > 0:\n",
    "            print(f\"🔴 All error number: {error_count} (из {len(data)})\")\n",
    "        \n",
    "        return formatted_data\n",
    "\n",
    "    def save_to_jsonl(self, \n",
    "                     data: List[Dict], \n",
    "                     output_path: str,\n",
    "                     format: str = \"doccano\") -> None:\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for item in tqdm(data, desc=\"Saved data\"):\n",
    "                if format == \"doccano\":\n",
    "                    # Format Doccano: {\"text\": \"...\", \"label\": [[start, end, tag], ...]}\n",
    "                    labels = [\n",
    "                        [ent[\"start\"], ent[\"end\"], ent[\"label\"]]\n",
    "                        for ent in item[\"entities\"]\n",
    "                    ]\n",
    "                    json.dump({\n",
    "                        \"text\": item[\"text\"],\n",
    "                        \"label\": labels,\n",
    "                        \"Comments\": item.get(\"comments\", [])\n",
    "                    }, f, ensure_ascii=False)\n",
    "                else:\n",
    "                    # Standart format\n",
    "                    json.dump(item, f, ensure_ascii=False)\n",
    "                f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd5f2bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Clear text\"\"\"\n",
    "    text = re.sub(r'\\n+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def adjust_annotations(text, annotations):\n",
    "    \"\"\"Correct annotation\"\"\"\n",
    "    cleaned_text = clean_text(text)\n",
    "    new_entities = []\n",
    "    \n",
    "    # Create list (start, end, label, entity_text)\n",
    "    entities_info = [(start, end, label, text[start:end]) \n",
    "                    for start, end, label in annotations['entities']]\n",
    "    \n",
    "    # Sort entity\n",
    "    entities_info.sort(key=lambda x: x[0])\n",
    "    \n",
    "    for start, end, label, entity_text in entities_info:\n",
    "        occurrences = [m.start() for m in re.finditer(re.escape(entity_text), text)]\n",
    "        \n",
    "        for occ_start in occurrences:\n",
    "            if occ_start == start:  \n",
    "                new_start = cleaned_text.find(entity_text)\n",
    "                if new_start != -1:\n",
    "                    new_end = new_start + len(entity_text)\n",
    "                    new_entities.append((new_start, new_end, label))\n",
    "                    cleaned_text = cleaned_text[:new_start] + ' ' * len(entity_text) + cleaned_text[new_end:]\n",
    "                break\n",
    "    \n",
    "    return {'entities': new_entities}\n",
    "\n",
    "class NERTrainer:\n",
    "    def __init__(self, \n",
    "                 model_name: str = \"ru_core_news_sm\", \n",
    "                 use_gpu: bool = True,\n",
    "                 blank_language: str = \"ru\",\n",
    "                 disable_pipes: Optional[List[str]] = None,\n",
    "                 transformer_name: Optional[str] = None):\n",
    "        self.use_gpu = use_gpu\n",
    "        self._setup_device()\n",
    "        \n",
    "        if transformer_name:\n",
    "            self.nlp = self._create_transformer_model(blank_language, transformer_name)\n",
    "        else:\n",
    "            self.nlp = self._load_model(model_name, blank_language, disable_pipes)\n",
    "            \n",
    "        self.ner = self._setup_ner_pipe(transformer_name)\n",
    "\n",
    "    def _create_transformer_model(self, lang: str, transformer_name: str):\n",
    "        \"\"\"Create model with transformer\"\"\"\n",
    "        nlp = spacy.blank(lang)\n",
    "        \n",
    "        # Add component transformer\n",
    "        config = {\n",
    "            \"model\": {\n",
    "                \"@architectures\": \"spacy-transformers.TransformerModel.v3\",\n",
    "                \"name\": transformer_name,\n",
    "                \"tokenizer_config\": {\"use_fast\": True},\n",
    "                \"transformer_config\": {\"output_hidden_states\": True}\n",
    "            }\n",
    "        }\n",
    "        nlp.add_pipe(\"transformer\", config=config)\n",
    "        \n",
    "        print(f\"Create transformer model {transformer_name}\")\n",
    "        return nlp\n",
    "        \n",
    "    def _setup_device(self) -> None:\n",
    "        \"\"\"Setting device (CPU/GPU)\"\"\"\n",
    "        if self.use_gpu and spacy.prefer_gpu():\n",
    "            spacy.require_gpu()\n",
    "            print(\"Used GPU\")\n",
    "        else:\n",
    "            print(\"⚠️ GPU not found, used CPU\")\n",
    "    \n",
    "    def _load_model(self, model_name: str, blank_language: str, disable_pipes: List[str]):\n",
    "        \"\"\"Load model and processing error\"\"\"\n",
    "        try:\n",
    "            if model_name.lower() == \"blank\":\n",
    "                return spacy.blank(blank_language)\n",
    "            elif Path(model_name).exists():\n",
    "                return spacy.load(model_name, disable=disable_pipes or [])\n",
    "            else:\n",
    "                return spacy.load(model_name, disable=disable_pipes or [])\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Model not found '{model_name}': {str(e)}\")\n",
    "    \n",
    "    def _setup_ner_pipe(self, transformer_name):\n",
    "        \"\"\"Setting NER component with transformer\"\"\"\n",
    "        if \"ner\" in self.nlp.pipe_names:\n",
    "            return self.nlp.get_pipe(\"ner\")\n",
    "    \n",
    "        # ДFor transformer model\n",
    "        if \"transformer\" in self.nlp.pipe_names:\n",
    "            return self.nlp.add_pipe(\n",
    "                \"ner\",\n",
    "                after=\"transformer\",\n",
    "                config={\n",
    "                    \"model\": {\n",
    "                        \"@architectures\": \"spacy.TransitionBasedParser.v2\",\n",
    "                        \"hidden_width\": 128,\n",
    "                        \"maxout_pieces\": 2,\n",
    "                        \"use_upper\": True\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "    \n",
    "        # For simple model\n",
    "        return self.nlp.add_pipe(\"ner\")\n",
    "    \n",
    "    def prepare_data(self, \n",
    "                    data: List[Dict],\n",
    "                    text_key: str = \"text\",\n",
    "                    entities_key: str = \"label\",\n",
    "                    start_offset_key: str = \"start_offset\",\n",
    "                    end_offset_key: str = \"end_offset\",\n",
    "                    label_key: str = \"label\") -> List[Tuple[str, Dict]]:\n",
    "        formatted_data = []\n",
    "        error_count = 0\n",
    "        \n",
    "        for item in tqdm(data, desc=\"Data preparation\"):\n",
    "            try:\n",
    "                text = item[text_key]\n",
    "                entities = []\n",
    "                \n",
    "                for ent in item.get(entities_key, []):\n",
    "                    # Check correct annotation\n",
    "                    if not all(k in ent for k in [start_offset_key, end_offset_key, label_key]):\n",
    "                        raise ValueError(f\"Incorrect annotation: {ent}\")\n",
    "                    \n",
    "                    start = ent[start_offset_key]\n",
    "                    end = ent[end_offset_key]\n",
    "                    \n",
    "                    # Validate position\n",
    "                    if not (0 <= start <= end <= len(text)):\n",
    "                        raise ValueError(f\"Incorrect position: {start}-{end} for text length {len(text)}\")\n",
    "                    \n",
    "                    entities.append((start, end, ent[label_key]))\n",
    "                \n",
    "                formatted_data.append((text, {\"entities\": entities}))\n",
    "            except Exception as e:\n",
    "                error_count += 1\n",
    "                print(f\"Error in element: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        if error_count > 0:\n",
    "            print(f\"All error count: {error_count} (for {len(data)})\")\n",
    "        \n",
    "        return formatted_data\n",
    "    \n",
    "    def train_test_split(self, \n",
    "                       data: List,\n",
    "                       test_size: float = 0.2,\n",
    "                       random_state: Optional[int] = None) -> Tuple[List, List]:\n",
    "        if random_state is not None:\n",
    "            random.seed(random_state)\n",
    "            \n",
    "        if not 0 < test_size < 1:\n",
    "            raise ValueError(\"test_size must be between 0 and 1\")\n",
    "            \n",
    "        shuffled = random.sample(data, len(data))\n",
    "        split_idx = int(len(data) * (1 - test_size))\n",
    "        return shuffled[:split_idx], shuffled[split_idx:]\n",
    "    \n",
    "    def add_labels(self, \n",
    "                  data: Optional[List[Tuple[str, Dict]]] = None,\n",
    "                  labels: Optional[List[str]] = None) -> None:\n",
    "        if labels is not None:\n",
    "            unique_labels = set(labels)\n",
    "        elif data is not None:\n",
    "            unique_labels = set()\n",
    "            for _, annotations in data:\n",
    "                for _, _, label in annotations[\"entities\"]:\n",
    "                    unique_labels.add(label)\n",
    "        else:\n",
    "            raise ValueError(\"You need data or labels\")\n",
    "        \n",
    "        for label in unique_labels:\n",
    "            self.ner.add_label(label)\n",
    "        \n",
    "        print(f\"Added labels: {sorted(unique_labels)}\")\n",
    "    \n",
    "    def train(self, \n",
    "             train_data: List[Tuple[str, Dict]],\n",
    "             epochs: int = 10,\n",
    "             batch_size: int = 8,\n",
    "             dropout: float = 0.5,\n",
    "             learning_rate: float = 0.001,\n",
    "             save_path: Optional[str] = None,\n",
    "             eval_data: Optional[List[Tuple[str, Dict]]] = None,\n",
    "             early_stopping: Optional[int] = None):\n",
    "    \n",
    "        # Init optimizer\n",
    "        optimizer = self.nlp.initialize()\n",
    "    \n",
    "        # Setting parameters for transformers\n",
    "        if \"transformer\" in self.nlp.pipe_names:\n",
    "            batch_size = min(batch_size, 4)\n",
    "            learning_rate = 1e-4\n",
    "            dropout = 0.1\n",
    "    \n",
    "        # Install learning rate\n",
    "        if hasattr(optimizer, \"learn_rate\"):\n",
    "            optimizer.learn_rate = learning_rate\n",
    "    \n",
    "        # init progress bar settings\n",
    "        best_f1 = -1\n",
    "        best_epoch = 0\n",
    "        history = {\"loss\": [], \"f1\": []}\n",
    "    \n",
    "        # Cycle train \n",
    "        for epoch in range(epochs):\n",
    "            losses = {}\n",
    "            random.shuffle(train_data)\n",
    "        \n",
    "            # Butch proccessing\n",
    "            batches = [train_data[i:i+batch_size] for i in range(0, len(train_data), batch_size)]\n",
    "        \n",
    "            for batch in tqdm(batches, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "                examples = []\n",
    "                for text, annotations in batch:\n",
    "                    doc = self.nlp.make_doc(text)\n",
    "                    example = Example.from_dict(doc, annotations)\n",
    "                    examples.append(example)\n",
    "            \n",
    "                self.nlp.update(examples, drop=dropout, losses=losses, sgd=optimizer)\n",
    "        \n",
    "            # Log and validation\n",
    "            epoch_loss = losses.get(\"ner\", 0)\n",
    "            history[\"loss\"].append(epoch_loss)\n",
    "            print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "            print(f\"📉 Loss: {epoch_loss:.3f}\")\n",
    "        \n",
    "            if eval_data:\n",
    "                metrics = self.evaluate(eval_data, verbose=False)\n",
    "                avg_f1 = sum(m[\"f\"] for m in metrics.values()) / len(metrics)\n",
    "                history[\"f1\"].append(avg_f1)\n",
    "                print(f\"📊 F1-score: {avg_f1:.3f}\")\n",
    "            \n",
    "                if save_path and avg_f1 > best_f1:\n",
    "                    best_f1 = avg_f1\n",
    "                    best_epoch = epoch\n",
    "                    self.nlp.to_disk(save_path)\n",
    "                    print(f\"Saved best model (F1: {best_f1:.3f})\")\n",
    "            \n",
    "                if early_stopping and (epoch - best_epoch) >= early_stopping:\n",
    "                    print(f\"🛑 Early stopping after {early_stopping} epoch with improvement\")\n",
    "                    break\n",
    "    \n",
    "        if eval_data is None and save_path:\n",
    "            self.nlp.to_disk(save_path)\n",
    "            print(\"Saved final model\")\n",
    "    \n",
    "        return history\n",
    "    \n",
    "    def evaluate(self, test_data: List[Tuple[str, Dict]], verbose: bool = True) -> Dict:\n",
    "        true_entities = []\n",
    "        pred_entities = []\n",
    "    \n",
    "        for text, annotations in tqdm(test_data, desc=\"🔍 Оценка модели\"):\n",
    "            # Entity from annotation\n",
    "            true = [(start, end, label) for start, end, label in annotations[\"entities\"]]\n",
    "            true_entities.append((text, true))\n",
    "        \n",
    "            # predicted entity\n",
    "            doc = self.nlp(text)\n",
    "            pred = [(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]\n",
    "            pred_entities.append((text, pred))\n",
    "    \n",
    "        # Calc metrics\n",
    "        metrics = self._calculate_metrics(true_entities, pred_entities)\n",
    "    \n",
    "        if verbose:\n",
    "            self._print_detailed_metrics(metrics)\n",
    "    \n",
    "        return metrics\n",
    "\n",
    "    def _calculate_metrics(self, true_entities, pred_entities):\n",
    "        \"\"\"Calc metrics for entities\"\"\"\n",
    "        metrics = defaultdict(lambda: {\"tp\": 0, \"fp\": 0, \"fn\": 0})\n",
    "    \n",
    "        for (true_text, true), (pred_text, pred) in zip(true_entities, pred_entities):\n",
    "            # Check position in text\n",
    "            if true_text != pred_text:\n",
    "                raise ValueError(\"The texts don't match!\")\n",
    "        \n",
    "            true_set = set(true)\n",
    "            pred_set = set(pred)\n",
    "        \n",
    "            # Calc TP, FP, FN for entity type\n",
    "            for label in set([e[2] for e in true] + [e[2] for e in pred]):\n",
    "                tp = len([e for e in true if e in pred and e[2] == label])\n",
    "                fp = len([e for e in pred if e not in true and e[2] == label])\n",
    "                fn = len([e for e in true if e not in pred and e[2] == label])\n",
    "            \n",
    "                metrics[label][\"tp\"] += tp\n",
    "                metrics[label][\"fp\"] += fp\n",
    "                metrics[label][\"fn\"] += fn\n",
    "    \n",
    "        # Calc precision, recall, f1 for each entity type\n",
    "        result = {}\n",
    "        for label, counts in metrics.items():\n",
    "            tp, fp, fn = counts[\"tp\"], counts[\"fp\"], counts[\"fn\"]\n",
    "            p = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            r = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            f1 = 2 * (p * r) / (p + r) if (p + r) > 0 else 0\n",
    "        \n",
    "            result[label] = {\n",
    "                \"precision\": p,\n",
    "                \"recall\": r,\n",
    "                \"f1\": f1,\n",
    "                \"support\": tp + fn,\n",
    "                \"tp\": tp,\n",
    "                \"fp\": fp,\n",
    "                \"fn\": fn\n",
    "            }\n",
    "    \n",
    "        return result\n",
    "\n",
    "    def _print_detailed_metrics(self, metrics):\n",
    "        print(\"\\nMetrics details:\")\n",
    "        print(\"{:<20} {:<10} {:<10} {:<10} {:<10}\".format(\n",
    "            \"Тип\", \"Precision\", \"Recall\", \"F1\", \"Support\"))\n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "        for label, values in metrics.items():\n",
    "            print(\"{:<20} {:<10.3f} {:<10.3f} {:<10.3f} {:<10}\".format(\n",
    "                label,\n",
    "                values[\"precision\"],\n",
    "                values[\"recall\"],\n",
    "                values[\"f1\"],\n",
    "                values[\"support\"]))\n",
    "    \n",
    "        # Micro-average\n",
    "        total_tp = sum(m[\"tp\"] for m in metrics.values())\n",
    "        total_fp = sum(m[\"fp\"] for m in metrics.values())\n",
    "        total_fn = sum(m[\"fn\"] for m in metrics.values())\n",
    "    \n",
    "        micro_p = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0\n",
    "        micro_r = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
    "        micro_f1 = 2 * (micro_p * micro_r) / (micro_p + micro_r) if (micro_p + micro_r) > 0 else 0\n",
    "    \n",
    "        print(\"\\nTotal final metrics (micro-average):\")\n",
    "        print(f\"Precision: {micro_p:.3f}\")\n",
    "        print(f\"Recall: {micro_r:.3f}\")\n",
    "        print(f\"F1-score: {micro_f1:.3f}\")\n",
    "\n",
    "    def _print_detailed_metrics(self, metrics):\n",
    "        \"\"\"Details\"\"\"\n",
    "        print(\"\\nDetails:\")\n",
    "        print(\"{:<20} {:<10} {:<10} {:<10} {:<10}\".format(\n",
    "            \"Тип\", \"Precision\", \"Recall\", \"F1\", \"Support\"))\n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "        for label, values in metrics.items():\n",
    "            print(\"{:<20} {:<10.3f} {:<10.3f} {:<10.3f} {:<10}\".format(\n",
    "                label,\n",
    "                values[\"precision\"],\n",
    "                values[\"recall\"],\n",
    "                values[\"f1\"],\n",
    "                values[\"support\"]))\n",
    "    \n",
    "        # Micro-average\n",
    "        total_tp = sum(m[\"tp\"] for m in metrics.values())\n",
    "        total_fp = sum(m[\"fp\"] for m in metrics.values())\n",
    "        total_fn = sum(m[\"fn\"] for m in metrics.values())\n",
    "    \n",
    "        micro_p = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0\n",
    "        micro_r = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
    "        micro_f1 = 2 * (micro_p * micro_r) / (micro_p + micro_r) if (micro_p + micro_r) > 0 else 0\n",
    "    \n",
    "        print(\"\\nTotal final metrics (micro-average):\")\n",
    "        print(f\"Precision: {micro_p:.3f}\")\n",
    "        print(f\"Recall: {micro_r:.3f}\")\n",
    "        print(f\"F1-score: {micro_f1:.3f}\")\n",
    "    \n",
    "    def predict(self, \n",
    "               text: str,\n",
    "               return_doc: bool = False) -> Union[List[Tuple[str, str, int, int]], \"spacy.tokens.Doc\"]:\n",
    "        doc = self.nlp(text)\n",
    "        if return_doc:\n",
    "            return doc\n",
    "        return [(ent.text, ent.label_, ent.start_char, ent.end_char) for ent in doc.ents]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b26a7a92-6fa2-4d49-b646-b33b7d576b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e9cf94222941799f930fb9bbe7d34b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload data: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succes upload 2051 rows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b5e5f31b26431da3379f7dccac48a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload data: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succes upload 879 raw\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2f810b62b046828367c84a81e3b1ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prepare data:   0%|          | 0/2051 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in element: incorrect position: 117-121 for text length 114. Text: ''\n",
      "Error in element: incorrect position: 262-267 for text length 259. Text: ''\n",
      "Total error count: 2 (from 2051)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5d7f74fcef4840aa8c2e4d4b8c3976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Prepare data:   0%|          | 0/879 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ GPU not support, used CPU\n",
      "Примеры обучающих данных: [('лист нержавеющий 4 x 1500 x 3000 mm aisi 201 12х15г9нд г / к матовый\\n\\n\\nлист нержавеющий 8 x 1500 x 3000 mm aisi 201 12х15г9нд г / к матовый\\n\\n\\nлист нержавеющий 1.5 x 1000 x 2000 mm aisi 201 12х15г9нд х / к шлифованный\\n\\n\\nлист нержавеющий 2 x 1000 x 2000 mm aisi 201 12х15г9нд г / к просечно - вытяжной пвл\\n\\n\\nлист нержавеющий 4 x 1000 x 2000 mm aisi 201 12х15г9нд г / к просечно - вытяжной пвл', {'entities': [(0, 4, 'product'), (5, 16, 'material'), (17, 18, 'thickness'), (21, 25, 'width'), (28, 32, 'length'), (36, 44, 'mark_steel_aisi'), (45, 54, 'mark_steal'), (55, 60, 'tehnology'), (61, 68, 'color'), (71, 75, 'product'), (76, 87, 'material'), (88, 89, 'thickness'), (92, 96, 'width'), (99, 103, 'length'), (107, 115, 'mark_steel_aisi'), (116, 125, 'mark_steal'), (126, 131, 'tehnology'), (132, 139, 'color'), (142, 146, 'product'), (147, 158, 'material'), (159, 162, 'thickness'), (165, 169, 'width'), (172, 176, 'length'), (180, 188, 'mark_steel_aisi'), (189, 198, 'mark_steal'), (199, 204, 'tehnology'), (205, 216, 'coating'), (219, 223, 'product'), (224, 235, 'material'), (236, 237, 'thickness'), (240, 244, 'width'), (247, 251, 'length'), (255, 263, 'mark_steel_aisi'), (264, 273, 'mark_steal'), (274, 279, 'tehnology'), (280, 299, 'type'), (300, 303, 'mark'), (306, 310, 'product'), (311, 322, 'material'), (323, 324, 'thickness'), (327, 331, 'width'), (334, 338, 'length'), (342, 350, 'mark_steel_aisi'), (351, 360, 'mark_steal'), (361, 366, 'tehnology'), (367, 386, 'type'), (387, 390, 'mark')]})]\n",
      "Apply metrics: ['coating', 'color', 'country', 'form', 'height', 'height_big', 'height_small', 'inner_diameter', 'length', 'manufacturer', 'mark', 'mark_steal', 'mark_steel_aisi', 'material', 'outer_diameter', 'package', 'precision', 'product', 'purpose', 'standart_en', 'standart_gost', 'standart_tu', 'strength_class', 'strength_class_old', 'tehnology', 'thickness', 'type', 'width']\n",
      "\n",
      "Train data length: 2049\n",
      "Test data length: 879\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8736150e56f143d68dd9d40097754ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/40\n",
      "📉 Loss: 34751.421\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a09d3a2c05b4756ab28d451cc455b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/40\n",
      "📉 Loss: 17453.279\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80f6b6e74fc4bbe875152dc0d5f83b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 3/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/40\n",
      "📉 Loss: 13180.380\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c541b3978be4c6a961f2dcf3df64576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/40\n",
      "📉 Loss: 11255.004\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a428833b9a394656a25ff6aa4e421d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/40\n",
      "📉 Loss: 9928.187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44022b1976d04dc995bdee0a94f00c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/40\n",
      "📉 Loss: 9012.005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068a4c6193684fb3b0b9e9f878f091e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/40\n",
      "📉 Loss: 7986.002\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2e50bdad1844b09d1d33b43aa77fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/40\n",
      "📉 Loss: 7156.043\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e776713e4b814e2fbe5c44b4652513e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/40\n",
      "📉 Loss: 6830.694\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d5bdb15110d4fcca312d70cbcfae6a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/40\n",
      "📉 Loss: 6312.031\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa075c36c44748dd9e24b5f5d6f37e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/40\n",
      "📉 Loss: 5962.034\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633c4ebfaa1543e59c41f9aa472e469b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/40\n",
      "📉 Loss: 5555.889\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8d8acc731c45f69e688123146456ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13/40\n",
      "📉 Loss: 5437.939\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a68f4c3e5cc4ba98183aa2ffb5281df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/40\n",
      "📉 Loss: 5274.134\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5283747d4d3445c0af6a26fd0eaa9db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 15/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/40\n",
      "📉 Loss: 4979.238\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a0fbe8342741f089f462cde6c36f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16/40\n",
      "📉 Loss: 4765.407\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e069ff33954783940a418a170c1b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17/40\n",
      "📉 Loss: 4654.535\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd5f7ff59204ae6add7a59f28ce38c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18/40\n",
      "📉 Loss: 4375.937\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea356d05c964fd78ed4754397226626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19/40\n",
      "📉 Loss: 4364.238\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7d80bf3f6149589c72a8c1e3468dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/40\n",
      "📉 Loss: 4283.655\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19105e13583c42359bafa5951383345e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21/40\n",
      "📉 Loss: 4241.335\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f7c92c14e04350917c14f362c25fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22/40\n",
      "📉 Loss: 3984.289\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9c5e8c1f384da986be1dde6fb42449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23/40\n",
      "📉 Loss: 3888.364\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50fb175a3a442dab72c8200c07f05d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24/40\n",
      "📉 Loss: 4042.827\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c617cc64a704693ad63f87acbc0b7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25/40\n",
      "📉 Loss: 3962.687\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38674991f20842f38cecb8eab3a8dea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26/40\n",
      "📉 Loss: 3801.571\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e2a3d4ad654460a4f51bd32bddb197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27/40\n",
      "📉 Loss: 3854.330\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611b61d6d4eb4397bfb80b05870c6fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28/40\n",
      "📉 Loss: 3610.508\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aedf68188da2474f9f1a76a375383932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29/40\n",
      "📉 Loss: 3688.979\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c48fa188e8b84cd28dc8a9fc1694e343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30/40\n",
      "📉 Loss: 3604.925\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111d4cc6241540b690b2bffb49881856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 31/40\n",
      "📉 Loss: 3501.070\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae89017396ca42069d693329dbdad7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32/40\n",
      "📉 Loss: 3567.380\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7585bfccbe844ca9aaff8430256b5d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 33/40\n",
      "📉 Loss: 3380.647\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8409318a33454a9d8ab0192ffc372b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34/40\n",
      "📉 Loss: 3541.794\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c6c668b6274ee589c40410086fa51f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 35/40\n",
      "📉 Loss: 3528.954\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90df10d278bf4bb1aaccaf3b7123a5e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 36/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36/40\n",
      "📉 Loss: 3452.260\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3ccbbee28c453aa305e29b7afb31a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 37/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 37/40\n",
      "📉 Loss: 3507.874\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa16d02a4594bfbb2c6fb6b14314f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 38/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38/40\n",
      "📉 Loss: 3424.018\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4f5b56be8648eb88922e70677f5ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 39/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 39/40\n",
      "📉 Loss: 3345.640\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa9f60aa8704890aae4a5c888787f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 40/40:   0%|          | 0/2049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40/40\n",
      "📉 Loss: 3399.545\n",
      "Saved final model\n",
      "Train time:  7203.317417383194  c\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f683e04784fb4fa5b21ecd13cc2f0566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "🔍 Evaluate model:   0%|          | 0/879 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Details:\n",
      "Тип                  Precision  Recall     F1         Support \n",
      "------------------------------------------------------------\n",
      "length               0.965      0.953      0.959      1236      \n",
      "tehnology            0.977      0.977      0.977      1017      \n",
      "product              0.994      0.991      0.993      4421      \n",
      "thickness            0.991      0.989      0.990      2812      \n",
      "color                0.960      0.960      0.960      100       \n",
      "coating              0.970      0.959      0.965      171       \n",
      "mark_steal           0.980      0.979      0.980      2724      \n",
      "material             0.980      0.992      0.986      1940      \n",
      "mark_steel_aisi      0.988      0.988      0.988      603       \n",
      "width                0.967      0.975      0.971      1869      \n",
      "type                 0.982      0.989      0.985      1862      \n",
      "mark                 0.915      0.933      0.924      403       \n",
      "height               0.942      0.921      0.931      579       \n",
      "form                 0.995      0.978      0.986      224       \n",
      "standart_gost        0.986      0.990      0.988      1525      \n",
      "manufacturer         0.933      0.947      0.940      132       \n",
      "country              0.958      0.920      0.939      25        \n",
      "standart_en          0.981      0.990      0.986      310       \n",
      "package              0.967      0.967      0.967      30        \n",
      "inner_diameter       0.975      0.982      0.978      1460      \n",
      "purpose              0.947      0.857      0.900      42        \n",
      "height_big           0.898      0.934      0.916      198       \n",
      "standart_tu          1.000      1.000      1.000      84        \n",
      "outer_diameter       0.971      0.948      0.959      524       \n",
      "strength_class       0.966      0.911      0.938      124       \n",
      "strength_class_old   0.905      0.987      0.944      77        \n",
      "height_small         1.000      0.111      0.200      9         \n",
      "precision            1.000      1.000      1.000      40        \n",
      "\n",
      "total metric (micro-average):\n",
      "Precision: 0.979\n",
      "Recall: 0.979\n",
      "F1-score: 0.979\n",
      "\n",
      "Metrics in total:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to dict.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m metrics \u001b[38;5;241m=\u001b[39m trainer_blank_empty\u001b[38;5;241m.\u001b[39mevaluate(formatted_test)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mМетрики на тестовой выборке:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecall: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1-score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported format string passed to dict.__format__"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "processor = DataProcessor()\n",
    "\n",
    "# Upload data\n",
    "train_data = processor.load_data(\"../../data/jsonl/dataset_jsonl_train.jsonl\")\n",
    "test_data = processor.load_data(\"../../data/jsonl/dataset_jsonl_test.jsonl\")\n",
    "\n",
    "# Подготовка для обучения\n",
    "formatted_train = processor.prepare_data(train_data)\n",
    "formatted_test = processor.prepare_data(test_data) if test_data else None\n",
    "\n",
    "time_start = time.time()\n",
    "# Инициализация тренера\n",
    "trainer_blank_empty = NERTrainer(\n",
    "    model_name=\"blank\",\n",
    "    blank_language=\"ru\",\n",
    ")\n",
    "\n",
    "# Добавление меток ДО разделения (теперь используем подготовленные данные)\n",
    "print(\"Примеры обучающих данных:\", formatted_train[:1])  # покажем первый пример для проверки\n",
    "trainer_blank_empty.add_labels(formatted_train)\n",
    "\n",
    "print(f\"\\nРазмер обучающей выборки: {len(formatted_train)}\")\n",
    "print(f\"Размер тестовой выборки: {len(formatted_test) if formatted_test else 0}\")\n",
    "\n",
    "# Обучение модели (увеличим epochs для лучшего качества)\n",
    "trainer_blank_empty.train(\n",
    "    formatted_train, \n",
    "    epochs=40,\n",
    "    batch_size=1,  \n",
    "    save_path=r\"C:\\Users\\mezhonnyy\\Desktop\\Решения\\NER\\model\\NER_final\\data\\jsonl\\model\"\n",
    ")\n",
    "print('Train time: ', time.time() - time_start, ' c')\n",
    "# Оценка модели (если есть тестовая выборка)\n",
    "time_start = time.time()\n",
    "if formatted_test:\n",
    "    metrics = trainer_blank_empty.evaluate(formatted_test)\n",
    "    print(\"\\nМетрики на тестовой выборке:\")\n",
    "    print(f\"Precision: {metrics['precision']:.2f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.2f}\")\n",
    "    print(f\"F1-score: {metrics['f1_score']:.2f}\")\n",
    "else:\n",
    "    print(\"\\nТестовая выборка не предоставлена, оценка не выполнена\")\n",
    "print('Inference time: ', time.time() - time_start, ' c')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d6639620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:  122.83794498443604  c\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a5a5c345934b48983eaf029370934f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "🔍 Оценка модели:   0%|          | 0/879 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Подробные метрики:\n",
      "Тип                  Precision  Recall     F1         Поддержка \n",
      "------------------------------------------------------------\n",
      "length               0.965      0.953      0.959      1236      \n",
      "tehnology            0.977      0.977      0.977      1017      \n",
      "product              0.994      0.991      0.993      4421      \n",
      "thickness            0.991      0.989      0.990      2812      \n",
      "color                0.960      0.960      0.960      100       \n",
      "coating              0.970      0.959      0.965      171       \n",
      "mark_steal           0.980      0.979      0.980      2724      \n",
      "material             0.980      0.992      0.986      1940      \n",
      "mark_steel_aisi      0.988      0.988      0.988      603       \n",
      "width                0.967      0.975      0.971      1869      \n",
      "type                 0.982      0.989      0.985      1862      \n",
      "mark                 0.915      0.933      0.924      403       \n",
      "height               0.942      0.921      0.931      579       \n",
      "form                 0.995      0.978      0.986      224       \n",
      "standart_gost        0.986      0.990      0.988      1525      \n",
      "manufacturer         0.933      0.947      0.940      132       \n",
      "country              0.958      0.920      0.939      25        \n",
      "standart_en          0.981      0.990      0.986      310       \n",
      "package              0.967      0.967      0.967      30        \n",
      "inner_diameter       0.975      0.982      0.978      1460      \n",
      "purpose              0.947      0.857      0.900      42        \n",
      "height_big           0.898      0.934      0.916      198       \n",
      "standart_tu          1.000      1.000      1.000      84        \n",
      "outer_diameter       0.971      0.948      0.959      524       \n",
      "strength_class       0.966      0.911      0.938      124       \n",
      "strength_class_old   0.905      0.987      0.944      77        \n",
      "height_small         1.000      0.111      0.200      9         \n",
      "precision            1.000      1.000      1.000      40        \n",
      "\n",
      "🔍 Итоговые метрики (micro-average):\n",
      "Precision: 0.979\n",
      "Recall: 0.979\n",
      "F1-score: 0.979\n",
      "Inference time:  8.277688264846802  c\n",
      "Макро-усредненные метрики (все классы равны):\n",
      "Macro-Precision: 0.9676\n",
      "Macro-Recall: 0.9332\n",
      "Macro-F1: 0.9375\n",
      "\n",
      "Взвешенные метрики (учитывают размер классов):\n",
      "Weighted Precision: 0.9790\n",
      "Weighted Recall: 0.9793\n",
      "Weighted F1: 0.9790\n",
      "\n",
      "Микро-усредненные метрики:\n",
      "Micro-Precision: 0.9790\n",
      "Micro-Recall: 0.9793\n",
      "Micro-F1: 0.9790\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print('Train time: ', time.time() - time_start, ' c')\n",
    "# Оценка модели (если есть тестовая выборка)\n",
    "time_start = time.time()\n",
    "if formatted_test:\n",
    "    metrics = trainer_blank_empty.evaluate(formatted_test)\n",
    "print('Inference time: ', time.time() - time_start, ' c')    \n",
    "\n",
    "# Создаем DataFrame и фильтруем классы без поддержки\n",
    "df = pd.DataFrame.from_dict(metrics, orient='index')\n",
    "#df = df[df['support'] > 0]  # Игнорируем классы с support=0\n",
    "\n",
    "# 1. Макро-усредненные метрики (все классы равнозначны)\n",
    "macro_precision = df['precision'].mean()\n",
    "macro_recall = df['recall'].mean()\n",
    "macro_f1 = df['f1'].mean()\n",
    "\n",
    "print(\"Макро-усредненные метрики (все классы равны):\")\n",
    "print(f\"Macro-Precision: {macro_precision:.4f}\")\n",
    "print(f\"Macro-Recall: {macro_recall:.4f}\")\n",
    "print(f\"Macro-F1: {macro_f1:.4f}\\n\")\n",
    "\n",
    "# 2. Взвешенные метрики (учитывают размер классов)\n",
    "total_support = df['support'].sum()\n",
    "weighted_precision = (df['precision'] * df['support']).sum() / total_support\n",
    "weighted_recall = (df['recall'] * df['support']).sum() / total_support\n",
    "weighted_f1 = (df['f1'] * df['support']).sum() / total_support\n",
    "\n",
    "print(\"Взвешенные метрики (учитывают размер классов):\")\n",
    "print(f\"Weighted Precision: {weighted_precision:.4f}\")\n",
    "print(f\"Weighted Recall: {weighted_recall:.4f}\")\n",
    "print(f\"Weighted F1: {weighted_f1:.4f}\\n\")\n",
    "\n",
    "# 3. Микро-усредненные метрики (альтернативный расчет)\n",
    "micro_precision = weighted_precision  # Для classification report они совпадают\n",
    "micro_recall = weighted_recall\n",
    "micro_f1 = weighted_f1\n",
    "\n",
    "print(\"Микро-усредненные метрики:\")\n",
    "print(f\"Micro-Precision: {micro_precision:.4f}\")\n",
    "print(f\"Micro-Recall: {micro_recall:.4f}\")\n",
    "print(f\"Micro-F1: {micro_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0e7fd7-0c39-4139-9f50-75baa6a900df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda95157f3314f248a0063aefdc893fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "📥 Загрузка данных: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Успешно загружено 2051 записей\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9dcdda129742b08c380ad268aaa98a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "📥 Загрузка данных: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Успешно загружено 879 записей\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12cc51464dff40a3b5721f750c1406b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "🔧 Подготовка данных:   0%|          | 0/2051 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Ошибка в элементе: Некорректные позиции: 117-121 для текста длины 114. Текст: ''\n",
      "⚠️ Ошибка в элементе: Некорректные позиции: 262-267 для текста длины 259. Текст: ''\n",
      "🔴 Всего ошибок: 2 (из 2051)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4955738b0f624bcca2747db4dbddcea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "🔧 Подготовка данных:   0%|          | 0/879 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ GPU не доступен, используется CPU\n",
      "✅ Создана трансформерная модель с DeepPavlov/rubert-base-cased\n",
      "Примеры обучающих данных: [('лист нержавеющий 4 x 1500 x 3000 mm aisi 201 12х15г9нд г / к матовый\\n\\n\\nлист нержавеющий 8 x 1500 x 3000 mm aisi 201 12х15г9нд г / к матовый\\n\\n\\nлист нержавеющий 1.5 x 1000 x 2000 mm aisi 201 12х15г9нд х / к шлифованный\\n\\n\\nлист нержавеющий 2 x 1000 x 2000 mm aisi 201 12х15г9нд г / к просечно - вытяжной пвл\\n\\n\\nлист нержавеющий 4 x 1000 x 2000 mm aisi 201 12х15г9нд г / к просечно - вытяжной пвл', {'entities': [(0, 4, 'product'), (5, 16, 'material'), (17, 18, 'thickness'), (21, 25, 'width'), (28, 32, 'length'), (36, 44, 'mark_steel_aisi'), (45, 54, 'mark_steal'), (55, 60, 'tehnology'), (61, 68, 'color'), (71, 75, 'product'), (76, 87, 'material'), (88, 89, 'thickness'), (92, 96, 'width'), (99, 103, 'length'), (107, 115, 'mark_steel_aisi'), (116, 125, 'mark_steal'), (126, 131, 'tehnology'), (132, 139, 'color'), (142, 146, 'product'), (147, 158, 'material'), (159, 162, 'thickness'), (165, 169, 'width'), (172, 176, 'length'), (180, 188, 'mark_steel_aisi'), (189, 198, 'mark_steal'), (199, 204, 'tehnology'), (205, 216, 'coating'), (219, 223, 'product'), (224, 235, 'material'), (236, 237, 'thickness'), (240, 244, 'width'), (247, 251, 'length'), (255, 263, 'mark_steel_aisi'), (264, 273, 'mark_steal'), (274, 279, 'tehnology'), (280, 299, 'type'), (300, 303, 'mark'), (306, 310, 'product'), (311, 322, 'material'), (323, 324, 'thickness'), (327, 331, 'width'), (334, 338, 'length'), (342, 350, 'mark_steel_aisi'), (351, 360, 'mark_steal'), (361, 366, 'tehnology'), (367, 386, 'type'), (387, 390, 'mark')]})]\n",
      "🏷 Добавлены метки: ['coating', 'color', 'country', 'form', 'height', 'height_big', 'height_small', 'inner_diameter', 'length', 'manufacturer', 'mark', 'mark_steal', 'mark_steel_aisi', 'material', 'outer_diameter', 'package', 'precision', 'product', 'purpose', 'standart_en', 'standart_gost', 'standart_tu', 'strength_class', 'strength_class_old', 'tehnology', 'thickness', 'type', 'width']\n",
      "\n",
      "Размер обучающей выборки: 2049\n",
      "Размер тестовой выборки: 879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cca332e427046da907fce62fcf70be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 1/10:   0%|          | 0/513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 1/10\n",
      "📉 Loss: 59980.936\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc7e96c4ef348a4b99869af303e86e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 2/10:   0%|          | 0/513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 2/10\n",
      "📉 Loss: 21648.147\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7775c699af6e422c98f02599acc815ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 3/10:   0%|          | 0/513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 3/10\n",
      "📉 Loss: 12628.520\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da538bca59f84833a5d324e053b566ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 4/10:   0%|          | 0/513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 4/10\n",
      "📉 Loss: 8729.204\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a395a7b8a1348c489f0e9612b58149c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 5/10:   0%|          | 0/513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 5/10\n",
      "📉 Loss: 6783.503\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93dd706a26064c189b7815a3f9a5dbba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 6/10:   0%|          | 0/513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 6/10\n",
      "📉 Loss: 5536.863\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "156d1506177148aa970df14253fd766f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 7/10:   0%|          | 0/513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 7/10\n",
      "📉 Loss: 4647.616\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1e213945e64bbc8fab6b4d2523fae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 8/10:   0%|          | 0/513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 8/10\n",
      "📉 Loss: 4039.089\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4565a22d4c4411082157aa1b688919c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 9/10:   0%|          | 0/513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Эпоха 9/10\n",
      "📉 Loss: 3319.055\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985076d3840e40ba848a7a9ece8c540d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Эпоха 10/10:   0%|          | 0/513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processor = DataProcessor()\n",
    "\n",
    "# Загрузка данных\n",
    "train_data = processor.load_data(\"../../data/jsonl/dataset_jsonl_train.jsonl\")\n",
    "test_data = processor.load_data(\"../../data/jsonl/dataset_jsonl_test.jsonl\")\n",
    "\n",
    "# Подготовка для обучения\n",
    "formatted_train = processor.prepare_data(train_data)\n",
    "formatted_test = processor.prepare_data(test_data) if test_data else None\n",
    "\n",
    "time_start = time.time()\n",
    "# Инициализация тренера\n",
    "trainer_blank_empty = NERTrainer(\n",
    "    blank_language=\"ru\",\n",
    "    transformer_name=\"DeepPavlov/rubert-base-cased\"\n",
    ")\n",
    "\n",
    "# Добавление меток ДО разделения (теперь используем подготовленные данные)\n",
    "print(\"Примеры обучающих данных:\", formatted_train[:1])  # покажем первый пример для проверки\n",
    "trainer_blank_empty.add_labels(formatted_train)\n",
    "\n",
    "print(f\"\\nРазмер обучающей выборки: {len(formatted_train)}\")\n",
    "print(f\"Размер тестовой выборки: {len(formatted_test) if formatted_test else 0}\")\n",
    "\n",
    "# Обучение модели (увеличим epochs для лучшего качества)\n",
    "trainer_blank_empty.train(\n",
    "    formatted_train, \n",
    "    epochs=10,\n",
    "    batch_size=16,  \n",
    "    save_path=r\"C:\\Users\\mezhonnyy\\Desktop\\Решения\\NER\\model\\NER_final\\data\\jsonl\\model\"\n",
    ")\n",
    "print('Train time: ', time.time() - time_start, ' c')\n",
    "# Оценка модели (если есть тестовая выборка)\n",
    "time_start = time.time()\n",
    "if formatted_test:\n",
    "    metrics = trainer_blank_empty.evaluate(formatted_test)\n",
    "    print(\"\\nМетрики на тестовой выборке:\")\n",
    "    print(f\"Precision: {metrics['precision']:.2f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.2f}\")\n",
    "    print(f\"F1-score: {metrics['f1_score']:.2f}\")\n",
    "else:\n",
    "    print(\"\\nТестовая выборка не предоставлена, оценка не выполнена\")\n",
    "print('Inference time: ', time.time() - time_start, ' c')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a6743839-f2b7-4218-970a-25869be94aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('купить', 'product', 0, 6),\n",
       " ('шестигранник', 'product', 7, 19),\n",
       " ('калибр', 'type', 20, 26),\n",
       " ('ст40x 27', 'mark_steal', 27, 35),\n",
       " ('гост 8560 - 78', 'standart_gost', 36, 50),\n",
       " ('4543 - 2016', 'standart_gost', 52, 63),\n",
       " ('95', 'width', 76, 78)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_blank.predict('купить шестигранник калибр ст40x 27 гост 8560 - 78, 4543 - 2016 цена 013568-95')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fc4399-8b0d-4fcf-81b7-46d4ba8f6d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_blank_empty.predict('купить шестигранник калибр ст40x 27 гост 8560 - 78, 4543 - 2016 цена 013568-95')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
